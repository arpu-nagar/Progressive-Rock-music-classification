{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arpan/miniconda3/envs/prog/lib/python3.10/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1c8k6cQ0P9HgkfoxgZx5jbn6e-6v0JRTO\n",
      "From (redirected): https://drive.google.com/uc?id=1c8k6cQ0P9HgkfoxgZx5jbn6e-6v0JRTO&confirm=t&uuid=218ef743-87f4-4f2a-b6f5-a4df6cc307ac\n",
      "To: /home/arpan/prog-rock/training_data.zip\n",
      "100%|██████████████████████████████████████| 2.51G/2.51G [00:31<00:00, 80.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# !gdown --id 1c8k6cQ0P9HgkfoxgZx5jbn6e-6v0JRTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  training_data.zip\n",
      "  inflating: ./content/non_progressive_rock_songs_tensor.pt  \n",
      "  inflating: ./content/progressive_rock_songs_tensor.pt  \n"
     ]
    }
   ],
   "source": [
    "# !mkdir content\n",
    "# !unzip -j training_data.zip -d ./content\n",
    "\n",
    "# we have the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CUDA Version is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "#training tensors\n",
    "prog_tensors = torch.load('./content/progressive_rock_songs_tensor.pt')\n",
    "non_prog_tensors = torch.load('./content/non_progressive_rock_songs_tensor.pt')\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "print(\" CUDA Version is \", get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_tensors = prog_tensors.float()\n",
    "non_prog_tensors = non_prog_tensors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat((prog_tensors, non_prog_tensors), dim=0)\n",
    "labels = torch.cat((torch.ones(prog_tensors.shape[0]), torch.zeros(non_prog_tensors.shape[0])), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Create TensorDataset from your data and labels\n",
    "train_dataset = TensorDataset(data, labels)\n",
    "# Create DataLoader for each dataset with the specified batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyConvNet(\n",
      "  (conv1): Conv1d(160, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (batchnorm1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(320, 640, kernel_size=(5,), stride=(1,), padding=(1,))\n",
      "  (batchnorm2): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv1d(640, 256, kernel_size=(5,), stride=(1,), padding=(1,))\n",
      "  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (batchnorm4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=27136, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# nn.Conv1d expects a batched 3-dimensional input in the shape [batch_size, in_channels, seq_length] or an unbatched 2-dimensional input in the shape [in_channels, seq_length]\n",
    "class MyConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyConvNet, self).__init__()\n",
    "\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=160, out_channels=320, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(320)\n",
    "        self.conv2 = nn.Conv1d(in_channels=320, out_channels=640, kernel_size=5, stride=1, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(640)\n",
    "        self.conv3 = nn.Conv1d(in_channels=640, out_channels=256, kernel_size=5, stride=1, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(256)\n",
    "        self.conv4 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(128)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(212*128, 200)  \n",
    "        self.fc2 = nn.Linear(200, 20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "        # Define activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU activation\n",
    "        x = self.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.batchnorm3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.batchnorm4(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Flatten the output of the convolutional layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers with ReLU activation\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyConvNet()\n",
    "print(model)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer (e.g., Adam optimizer with learning rate 0.001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [32, 320, 216]         153,920\n",
      "       BatchNorm1d-2             [32, 320, 216]             640\n",
      "              ReLU-3             [32, 320, 216]               0\n",
      "           Dropout-4             [32, 320, 216]               0\n",
      "            Conv1d-5             [32, 640, 214]       1,024,640\n",
      "       BatchNorm1d-6             [32, 640, 214]           1,280\n",
      "              ReLU-7             [32, 640, 214]               0\n",
      "           Dropout-8             [32, 640, 214]               0\n",
      "            Conv1d-9             [32, 256, 212]         819,456\n",
      "      BatchNorm1d-10             [32, 256, 212]             512\n",
      "             ReLU-11             [32, 256, 212]               0\n",
      "          Dropout-12             [32, 256, 212]               0\n",
      "           Conv1d-13             [32, 128, 212]          98,432\n",
      "      BatchNorm1d-14             [32, 128, 212]             256\n",
      "             ReLU-15             [32, 128, 212]               0\n",
      "          Dropout-16             [32, 128, 212]               0\n",
      "           Linear-17                  [32, 200]       5,427,400\n",
      "             ReLU-18                  [32, 200]               0\n",
      "          Dropout-19                  [32, 200]               0\n",
      "           Linear-20                   [32, 20]           4,020\n",
      "             ReLU-21                   [32, 20]               0\n",
      "          Dropout-22                   [32, 20]               0\n",
      "           Linear-23                    [32, 2]              42\n",
      "================================================================\n",
      "Total params: 7,530,598\n",
      "Trainable params: 7,530,598\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.22\n",
      "Forward/backward pass size (MB): 280.91\n",
      "Params size (MB): 28.73\n",
      "Estimated Total Size (MB): 313.86\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, (160,216), 32, \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CUDA Version is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "print(\" CUDA Version is \", get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyConvNet(\n",
      "  (conv1): Conv1d(160, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (batchnorm1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(320, 640, kernel_size=(5,), stride=(1,), padding=(1,))\n",
      "  (batchnorm2): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv1d(640, 256, kernel_size=(5,), stride=(1,), padding=(1,))\n",
      "  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (batchnorm4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=27136, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n",
      "Epoch: 0, Batch: 1, Loss: 0.7337, Accuracy: 34.38%, Precision: 0.00%\n",
      "Epoch: 0, Batch: 2, Loss: 2.1883, Accuracy: 40.62%, Precision: 42.42%\n",
      "Epoch: 0, Batch: 3, Loss: 0.8548, Accuracy: 44.79%, Precision: 44.12%\n",
      "Epoch: 0, Batch: 4, Loss: 0.6377, Accuracy: 50.00%, Precision: 45.95%\n",
      "Epoch: 0, Batch: 5, Loss: 0.9128, Accuracy: 48.75%, Precision: 51.02%\n",
      "Epoch: 0, Batch: 6, Loss: 0.6590, Accuracy: 51.56%, Precision: 53.42%\n",
      "Epoch: 0, Batch: 7, Loss: 0.8219, Accuracy: 50.00%, Precision: 50.00%\n",
      "Epoch: 0, Batch: 8, Loss: 0.8349, Accuracy: 51.17%, Precision: 52.50%\n",
      "Epoch: 0, Batch: 9, Loss: 0.6786, Accuracy: 50.69%, Precision: 52.08%\n",
      "Epoch: 0, Batch: 10, Loss: 0.7263, Accuracy: 50.62%, Precision: 51.85%\n",
      "Epoch: 0, Batch: 11, Loss: 0.7218, Accuracy: 51.14%, Precision: 52.81%\n",
      "Epoch: 0, Batch: 12, Loss: 0.6953, Accuracy: 51.04%, Precision: 52.28%\n",
      "Epoch: 0, Batch: 13, Loss: 0.6942, Accuracy: 50.96%, Precision: 52.15%\n",
      "Epoch: 0, Batch: 14, Loss: 0.7001, Accuracy: 51.34%, Precision: 52.31%\n",
      "Epoch: 0, Batch: 15, Loss: 0.7026, Accuracy: 51.67%, Precision: 53.12%\n",
      "Epoch: 0, Batch: 16, Loss: 0.7064, Accuracy: 51.56%, Precision: 53.16%\n",
      "Epoch: 0, Batch: 17, Loss: 0.7384, Accuracy: 50.92%, Precision: 50.60%\n",
      "Epoch: 0, Batch: 18, Loss: 0.7018, Accuracy: 50.87%, Precision: 50.97%\n",
      "Epoch: 0, Batch: 19, Loss: 0.6822, Accuracy: 50.82%, Precision: 51.34%\n",
      "Epoch: 0, Batch: 20, Loss: 0.7151, Accuracy: 50.94%, Precision: 51.85%\n",
      "Epoch: 0, Batch: 21, Loss: 0.6670, Accuracy: 51.19%, Precision: 51.97%\n",
      "Epoch: 0, Batch: 22, Loss: 0.6558, Accuracy: 51.56%, Precision: 52.63%\n",
      "Epoch: 0, Batch: 23, Loss: 0.6987, Accuracy: 51.63%, Precision: 53.08%\n",
      "Epoch: 0, Batch: 24, Loss: 0.7086, Accuracy: 51.69%, Precision: 53.72%\n",
      "Epoch: 0, Batch: 25, Loss: 0.6764, Accuracy: 52.12%, Precision: 54.46%\n",
      "Epoch: 0, Batch: 26, Loss: 0.6823, Accuracy: 52.16%, Precision: 55.06%\n",
      "Epoch: 0, Batch: 27, Loss: 0.7071, Accuracy: 51.85%, Precision: 54.15%\n",
      "Epoch: 0, Batch: 28, Loss: 0.6664, Accuracy: 52.01%, Precision: 54.64%\n",
      "Epoch: 0, Batch: 29, Loss: 0.6582, Accuracy: 52.26%, Precision: 55.38%\n",
      "Epoch: 0, Batch: 30, Loss: 0.6883, Accuracy: 52.40%, Precision: 55.30%\n",
      "Epoch: 0, Batch: 31, Loss: 0.6706, Accuracy: 52.52%, Precision: 55.16%\n",
      "Epoch: 0, Batch: 32, Loss: 0.7456, Accuracy: 52.54%, Precision: 54.59%\n",
      "Epoch: 0, Batch: 33, Loss: 0.8058, Accuracy: 52.08%, Precision: 54.05%\n",
      "Epoch: 0, Batch: 34, Loss: 0.7431, Accuracy: 52.21%, Precision: 53.86%\n",
      "Epoch: 0, Batch: 35, Loss: 0.6941, Accuracy: 52.23%, Precision: 53.49%\n",
      "Epoch: 0, Batch: 36, Loss: 0.7069, Accuracy: 52.52%, Precision: 53.88%\n",
      "Epoch: 0, Batch: 37, Loss: 0.7086, Accuracy: 52.28%, Precision: 53.85%\n",
      "Epoch: 0, Batch: 38, Loss: 0.6717, Accuracy: 52.55%, Precision: 54.36%\n",
      "Epoch: 0, Batch: 39, Loss: 0.6960, Accuracy: 52.48%, Precision: 54.04%\n",
      "Epoch: 0, Batch: 40, Loss: 0.6925, Accuracy: 52.73%, Precision: 54.08%\n",
      "Epoch: 0, Batch: 41, Loss: 0.6462, Accuracy: 53.05%, Precision: 54.53%\n",
      "Epoch: 0, Batch: 42, Loss: 0.6862, Accuracy: 53.20%, Precision: 54.79%\n",
      "Epoch: 0, Batch: 43, Loss: 0.6809, Accuracy: 53.42%, Precision: 55.30%\n",
      "Epoch: 0, Batch: 44, Loss: 0.6560, Accuracy: 53.48%, Precision: 54.93%\n",
      "Epoch: 0, Batch: 45, Loss: 0.6533, Accuracy: 53.54%, Precision: 54.96%\n",
      "Epoch: 0, Batch: 46, Loss: 0.6657, Accuracy: 53.60%, Precision: 55.11%\n",
      "Epoch: 0, Batch: 47, Loss: 0.6057, Accuracy: 53.99%, Precision: 55.20%\n",
      "Epoch: 0, Batch: 48, Loss: 0.6382, Accuracy: 54.10%, Precision: 55.07%\n",
      "Epoch: 0, Batch: 49, Loss: 0.7087, Accuracy: 54.02%, Precision: 55.14%\n",
      "Epoch: 0, Batch: 50, Loss: 0.6999, Accuracy: 54.00%, Precision: 55.39%\n",
      "Epoch: 0, Batch: 51, Loss: 0.6847, Accuracy: 53.86%, Precision: 55.08%\n",
      "Epoch: 0, Batch: 52, Loss: 0.6840, Accuracy: 53.91%, Precision: 55.03%\n",
      "Epoch: 0, Batch: 53, Loss: 0.6593, Accuracy: 54.01%, Precision: 55.16%\n",
      "Epoch: 0, Batch: 54, Loss: 0.7569, Accuracy: 53.70%, Precision: 54.93%\n",
      "Epoch: 0, Batch: 55, Loss: 0.6620, Accuracy: 53.75%, Precision: 54.91%\n",
      "Epoch: 0, Batch: 56, Loss: 0.6603, Accuracy: 53.74%, Precision: 54.87%\n",
      "Epoch: 0, Batch: 57, Loss: 0.6345, Accuracy: 53.73%, Precision: 54.61%\n",
      "Epoch: 0, Batch: 58, Loss: 0.6383, Accuracy: 53.93%, Precision: 54.85%\n",
      "Epoch: 0, Batch: 59, Loss: 0.6602, Accuracy: 53.87%, Precision: 54.70%\n",
      "Epoch: 0, Batch: 60, Loss: 0.6383, Accuracy: 53.85%, Precision: 54.47%\n",
      "Epoch: 0, Batch: 61, Loss: 0.6543, Accuracy: 53.89%, Precision: 54.45%\n",
      "Epoch: 0, Batch: 62, Loss: 0.6673, Accuracy: 53.93%, Precision: 54.47%\n",
      "Epoch: 0, Batch: 63, Loss: 0.6664, Accuracy: 53.77%, Precision: 54.08%\n",
      "Epoch: 0, Batch: 64, Loss: 0.6501, Accuracy: 53.96%, Precision: 54.29%\n",
      "Epoch: 0, Batch: 65, Loss: 0.7944, Accuracy: 53.80%, Precision: 54.19%\n",
      "Epoch: 0, Batch: 66, Loss: 0.6928, Accuracy: 53.79%, Precision: 54.05%\n",
      "Epoch: 0, Batch: 67, Loss: 0.6930, Accuracy: 53.78%, Precision: 54.10%\n",
      "Epoch: 0, Batch: 68, Loss: 0.6846, Accuracy: 53.81%, Precision: 54.01%\n",
      "Epoch: 0, Batch: 69, Loss: 0.6802, Accuracy: 53.67%, Precision: 53.93%\n",
      "Epoch: 0, Batch: 70, Loss: 0.6634, Accuracy: 53.53%, Precision: 53.66%\n",
      "Epoch: 0, Batch: 71, Loss: 0.6622, Accuracy: 53.48%, Precision: 53.50%\n",
      "Epoch: 0, Batch: 72, Loss: 0.6693, Accuracy: 53.43%, Precision: 53.57%\n",
      "Epoch: 0, Batch: 73, Loss: 0.7293, Accuracy: 53.30%, Precision: 53.45%\n",
      "Epoch: 0, Batch: 74, Loss: 0.6690, Accuracy: 53.38%, Precision: 53.57%\n",
      "Epoch: 0, Batch: 75, Loss: 0.7152, Accuracy: 53.54%, Precision: 53.89%\n",
      "Epoch: 0, Batch: 76, Loss: 0.6163, Accuracy: 53.62%, Precision: 53.85%\n",
      "Epoch: 0, Batch: 77, Loss: 0.6470, Accuracy: 53.69%, Precision: 54.03%\n",
      "Epoch: 0, Batch: 78, Loss: 0.6958, Accuracy: 53.85%, Precision: 54.39%\n",
      "Epoch: 0, Batch: 79, Loss: 0.6973, Accuracy: 53.76%, Precision: 54.07%\n",
      "Epoch: 0, Batch: 80, Loss: 0.6672, Accuracy: 53.67%, Precision: 53.79%\n",
      "Epoch: 0, Batch: 81, Loss: 0.6439, Accuracy: 53.78%, Precision: 53.97%\n",
      "Epoch: 0, Batch: 82, Loss: 0.6385, Accuracy: 53.89%, Precision: 54.14%\n",
      "Epoch: 0, Batch: 83, Loss: 0.6608, Accuracy: 53.88%, Precision: 53.99%\n",
      "Epoch: 0, Batch: 84, Loss: 0.7553, Accuracy: 53.91%, Precision: 54.11%\n",
      "Epoch: 0, Batch: 85, Loss: 0.6773, Accuracy: 54.08%, Precision: 54.34%\n",
      "Epoch: 0, Batch: 86, Loss: 0.6611, Accuracy: 54.18%, Precision: 54.26%\n",
      "Epoch: 0, Batch: 87, Loss: 0.6629, Accuracy: 54.13%, Precision: 54.25%\n",
      "Epoch: 0, Batch: 88, Loss: 0.6776, Accuracy: 54.19%, Precision: 54.44%\n",
      "Epoch: 0, Batch: 89, Loss: 0.7210, Accuracy: 54.07%, Precision: 54.52%\n",
      "Epoch: 0, Batch: 90, Loss: 0.6591, Accuracy: 53.99%, Precision: 54.74%\n",
      "Epoch: 0, Batch: 91, Loss: 0.6864, Accuracy: 53.95%, Precision: 54.74%\n",
      "Epoch: 0, Batch: 92, Loss: 0.6877, Accuracy: 54.01%, Precision: 54.95%\n",
      "Epoch: 0, Batch: 93, Loss: 0.6329, Accuracy: 54.17%, Precision: 55.17%\n",
      "Epoch: 0, Batch: 94, Loss: 0.7093, Accuracy: 54.12%, Precision: 55.14%\n",
      "Epoch: 0, Batch: 95, Loss: 0.7199, Accuracy: 54.08%, Precision: 55.10%\n",
      "Epoch: 0, Batch: 96, Loss: 0.6976, Accuracy: 54.10%, Precision: 55.28%\n",
      "Epoch: 0, Batch: 97, Loss: 0.6123, Accuracy: 54.28%, Precision: 55.56%\n",
      "Epoch: 0, Batch: 98, Loss: 0.6568, Accuracy: 54.34%, Precision: 55.48%\n",
      "Epoch: 0, Batch: 99, Loss: 0.6946, Accuracy: 54.36%, Precision: 55.60%\n",
      "Epoch: 0, Batch: 100, Loss: 0.6459, Accuracy: 54.53%, Precision: 55.72%\n",
      "Epoch: 0, Batch: 101, Loss: 0.7111, Accuracy: 54.55%, Precision: 55.58%\n",
      "Epoch: 0, Batch: 102, Loss: 0.7386, Accuracy: 54.41%, Precision: 55.37%\n",
      "Epoch: 0, Batch: 103, Loss: 0.7072, Accuracy: 54.37%, Precision: 55.30%\n",
      "Epoch: 0, Batch: 104, Loss: 0.6628, Accuracy: 54.45%, Precision: 55.35%\n",
      "Epoch: 0, Batch: 105, Loss: 0.6409, Accuracy: 54.52%, Precision: 55.35%\n",
      "Epoch: 0, Batch: 106, Loss: 0.6807, Accuracy: 54.60%, Precision: 55.34%\n",
      "Epoch: 0, Batch: 107, Loss: 0.6597, Accuracy: 54.64%, Precision: 55.33%\n",
      "Epoch: 0, Batch: 108, Loss: 0.6642, Accuracy: 54.60%, Precision: 55.20%\n",
      "Epoch: 0, Batch: 109, Loss: 0.6510, Accuracy: 54.73%, Precision: 55.43%\n",
      "Epoch: 0, Batch: 110, Loss: 0.6933, Accuracy: 54.72%, Precision: 55.40%\n",
      "Epoch: 0, Batch: 111, Loss: 0.6772, Accuracy: 54.70%, Precision: 55.34%\n",
      "Epoch: 0, Batch: 112, Loss: 0.7670, Accuracy: 54.58%, Precision: 55.24%\n",
      "Epoch: 0, Batch: 113, Loss: 0.6478, Accuracy: 54.62%, Precision: 55.25%\n",
      "Epoch: 0, Batch: 114, Loss: 0.7505, Accuracy: 54.61%, Precision: 55.17%\n",
      "Epoch: 0, Batch: 115, Loss: 0.6617, Accuracy: 54.62%, Precision: 55.21%\n",
      "Epoch: 0, Batch: 116, Loss: 0.6592, Accuracy: 54.55%, Precision: 55.14%\n",
      "Epoch: 0, Batch: 117, Loss: 0.6520, Accuracy: 54.67%, Precision: 55.42%\n",
      "Epoch: 0, Batch: 118, Loss: 0.6722, Accuracy: 54.66%, Precision: 55.46%\n",
      "Epoch: 0, Batch: 119, Loss: 0.6647, Accuracy: 54.65%, Precision: 55.55%\n",
      "Epoch: 0, Batch: 120, Loss: 0.6281, Accuracy: 54.79%, Precision: 55.77%\n",
      "Epoch: 0, Batch: 121, Loss: 0.6476, Accuracy: 54.80%, Precision: 55.72%\n",
      "Epoch: 0, Batch: 122, Loss: 0.6983, Accuracy: 54.74%, Precision: 55.67%\n",
      "Epoch: 0, Batch: 123, Loss: 0.6838, Accuracy: 54.70%, Precision: 55.51%\n",
      "Epoch: 0, Batch: 124, Loss: 0.7019, Accuracy: 54.59%, Precision: 55.33%\n",
      "Epoch: 0, Batch: 125, Loss: 0.6322, Accuracy: 54.62%, Precision: 55.32%\n",
      "Epoch: 0, Batch: 126, Loss: 0.6748, Accuracy: 54.56%, Precision: 55.30%\n",
      "Epoch: 0, Batch: 127, Loss: 0.6718, Accuracy: 54.53%, Precision: 55.34%\n",
      "Epoch: 0, Batch: 128, Loss: 0.6841, Accuracy: 54.49%, Precision: 55.29%\n",
      "Epoch: 0, Batch: 129, Loss: 0.6719, Accuracy: 54.53%, Precision: 55.27%\n",
      "Epoch: 0, Batch: 130, Loss: 0.6809, Accuracy: 54.54%, Precision: 55.20%\n",
      "Epoch: 0, Batch: 131, Loss: 0.6727, Accuracy: 54.46%, Precision: 55.03%\n",
      "Epoch: 0, Batch: 132, Loss: 0.6753, Accuracy: 54.43%, Precision: 54.82%\n",
      "Epoch: 0, Batch: 133, Loss: 0.6808, Accuracy: 54.42%, Precision: 54.89%\n",
      "Epoch: 0, Batch: 134, Loss: 0.7119, Accuracy: 54.29%, Precision: 54.71%\n",
      "Epoch: 0, Batch: 135, Loss: 0.6482, Accuracy: 54.24%, Precision: 54.66%\n",
      "Epoch: 0, Batch: 136, Loss: 0.6628, Accuracy: 54.18%, Precision: 54.77%\n",
      "Epoch: 0, Batch: 137, Loss: 0.6792, Accuracy: 54.20%, Precision: 54.78%\n",
      "Epoch: 0, Batch: 138, Loss: 0.6104, Accuracy: 54.35%, Precision: 54.99%\n",
      "Epoch: 0, Batch: 139, Loss: 0.6939, Accuracy: 54.34%, Precision: 55.10%\n",
      "Epoch: 0, Batch: 140, Loss: 0.6462, Accuracy: 54.37%, Precision: 55.08%\n",
      "Epoch: 0, Batch: 141, Loss: 0.6743, Accuracy: 54.41%, Precision: 55.24%\n",
      "Epoch: 0, Batch: 142, Loss: 0.6555, Accuracy: 54.42%, Precision: 55.21%\n",
      "Epoch: 0, Batch: 143, Loss: 0.7612, Accuracy: 54.37%, Precision: 55.12%\n",
      "Epoch: 0, Batch: 144, Loss: 0.6648, Accuracy: 54.34%, Precision: 55.09%\n",
      "Epoch: 0, Batch: 145, Loss: 0.6337, Accuracy: 54.42%, Precision: 55.23%\n",
      "Epoch: 0, Batch: 146, Loss: 0.6700, Accuracy: 54.37%, Precision: 55.27%\n",
      "Epoch: 0, Batch: 147, Loss: 0.6830, Accuracy: 54.29%, Precision: 55.20%\n",
      "Epoch: 0, Batch: 148, Loss: 0.6462, Accuracy: 54.33%, Precision: 55.22%\n",
      "Epoch: 0, Batch: 149, Loss: 0.6913, Accuracy: 54.34%, Precision: 55.21%\n",
      "Epoch: 0, Batch: 150, Loss: 0.6746, Accuracy: 54.40%, Precision: 55.28%\n",
      "Epoch: 0, Batch: 151, Loss: 0.6672, Accuracy: 54.39%, Precision: 55.24%\n",
      "Epoch: 0, Batch: 152, Loss: 0.6531, Accuracy: 54.42%, Precision: 55.28%\n",
      "Epoch: 0, Batch: 153, Loss: 0.6400, Accuracy: 54.43%, Precision: 55.32%\n",
      "Epoch: 0, Batch: 154, Loss: 0.7009, Accuracy: 54.36%, Precision: 55.24%\n",
      "Epoch: 0, Batch: 155, Loss: 0.5717, Accuracy: 54.46%, Precision: 55.37%\n",
      "Epoch: 0, Batch: 156, Loss: 0.6736, Accuracy: 54.41%, Precision: 55.22%\n",
      "Epoch: 0, Batch: 157, Loss: 0.6548, Accuracy: 54.42%, Precision: 55.30%\n",
      "Epoch: 0, Batch: 158, Loss: 0.6398, Accuracy: 54.47%, Precision: 55.31%\n",
      "Epoch: 0, Batch: 159, Loss: 0.5717, Accuracy: 54.56%, Precision: 55.34%\n",
      "Epoch: 0, Batch: 160, Loss: 0.5560, Accuracy: 54.71%, Precision: 55.58%\n",
      "Epoch: 0, Batch: 161, Loss: 0.7331, Accuracy: 54.68%, Precision: 55.53%\n",
      "Epoch: 0, Batch: 162, Loss: 0.7551, Accuracy: 54.67%, Precision: 55.56%\n",
      "Epoch: 0, Batch: 163, Loss: 0.6661, Accuracy: 54.68%, Precision: 55.50%\n",
      "Epoch: 0, Batch: 164, Loss: 0.6586, Accuracy: 54.73%, Precision: 55.51%\n",
      "Epoch: 0, Batch: 165, Loss: 0.6031, Accuracy: 54.77%, Precision: 55.61%\n",
      "Epoch: 0, Batch: 166, Loss: 0.6719, Accuracy: 54.78%, Precision: 55.67%\n",
      "Epoch: 0, Batch: 167, Loss: 0.5958, Accuracy: 54.87%, Precision: 55.77%\n",
      "Epoch: 0, Batch: 168, Loss: 0.6339, Accuracy: 54.91%, Precision: 55.80%\n",
      "Epoch: 0, Batch: 169, Loss: 0.6607, Accuracy: 54.96%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 170, Loss: 0.6386, Accuracy: 54.94%, Precision: 55.85%\n",
      "Epoch: 0, Batch: 171, Loss: 0.6663, Accuracy: 54.93%, Precision: 55.78%\n",
      "Epoch: 0, Batch: 172, Loss: 0.6479, Accuracy: 54.94%, Precision: 55.83%\n",
      "Epoch: 0, Batch: 173, Loss: 0.7430, Accuracy: 54.93%, Precision: 55.85%\n",
      "Epoch: 0, Batch: 174, Loss: 0.6362, Accuracy: 54.97%, Precision: 55.96%\n",
      "Epoch: 0, Batch: 175, Loss: 0.6711, Accuracy: 54.96%, Precision: 55.90%\n",
      "Epoch: 0, Batch: 176, Loss: 0.5903, Accuracy: 55.10%, Precision: 56.03%\n",
      "Epoch: 0, Batch: 177, Loss: 0.6594, Accuracy: 55.07%, Precision: 56.02%\n",
      "Epoch: 0, Batch: 178, Loss: 0.6456, Accuracy: 55.06%, Precision: 55.96%\n",
      "Epoch: 0, Batch: 179, Loss: 0.6958, Accuracy: 55.06%, Precision: 55.91%\n",
      "Epoch: 0, Batch: 180, Loss: 0.6752, Accuracy: 55.07%, Precision: 55.87%\n",
      "Epoch: 0, Batch: 181, Loss: 0.7390, Accuracy: 55.04%, Precision: 55.78%\n",
      "Epoch: 0, Batch: 182, Loss: 0.6084, Accuracy: 55.08%, Precision: 55.79%\n",
      "Epoch: 0, Batch: 183, Loss: 0.8371, Accuracy: 55.02%, Precision: 55.72%\n",
      "Epoch: 0, Batch: 184, Loss: 0.6401, Accuracy: 55.03%, Precision: 55.69%\n",
      "Epoch: 0, Batch: 185, Loss: 0.6655, Accuracy: 54.98%, Precision: 55.72%\n",
      "Epoch: 0, Batch: 186, Loss: 0.6527, Accuracy: 54.97%, Precision: 55.80%\n",
      "Epoch: 0, Batch: 187, Loss: 0.6857, Accuracy: 54.91%, Precision: 55.75%\n",
      "Epoch: 0, Batch: 188, Loss: 0.6652, Accuracy: 54.97%, Precision: 55.74%\n",
      "Epoch: 0, Batch: 189, Loss: 0.6788, Accuracy: 54.94%, Precision: 55.73%\n",
      "Epoch: 0, Batch: 190, Loss: 0.6850, Accuracy: 54.93%, Precision: 55.76%\n",
      "Epoch: 0, Batch: 191, Loss: 0.7071, Accuracy: 54.88%, Precision: 55.75%\n",
      "Epoch: 0, Batch: 192, Loss: 0.6451, Accuracy: 54.88%, Precision: 55.80%\n",
      "Epoch: 0, Batch: 193, Loss: 0.6954, Accuracy: 54.81%, Precision: 55.80%\n",
      "Epoch: 0, Batch: 194, Loss: 0.6706, Accuracy: 54.75%, Precision: 55.82%\n",
      "Epoch: 0, Batch: 195, Loss: 0.6574, Accuracy: 54.76%, Precision: 55.79%\n",
      "Epoch: 0, Batch: 196, Loss: 0.7667, Accuracy: 54.66%, Precision: 55.80%\n",
      "Epoch: 0, Batch: 197, Loss: 0.6699, Accuracy: 54.70%, Precision: 55.89%\n",
      "Epoch: 0, Batch: 198, Loss: 0.6793, Accuracy: 54.66%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 199, Loss: 0.6571, Accuracy: 54.70%, Precision: 55.91%\n",
      "Epoch: 0, Batch: 200, Loss: 0.6377, Accuracy: 54.73%, Precision: 55.93%\n",
      "Epoch: 0, Batch: 201, Loss: 0.6395, Accuracy: 54.74%, Precision: 55.91%\n",
      "Epoch: 0, Batch: 202, Loss: 0.6829, Accuracy: 54.70%, Precision: 55.90%\n",
      "Epoch: 0, Batch: 203, Loss: 0.6707, Accuracy: 54.74%, Precision: 55.99%\n",
      "Epoch: 0, Batch: 204, Loss: 0.7686, Accuracy: 54.64%, Precision: 55.87%\n",
      "Epoch: 0, Batch: 205, Loss: 0.6785, Accuracy: 54.63%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 206, Loss: 0.6775, Accuracy: 54.66%, Precision: 55.85%\n",
      "Epoch: 0, Batch: 207, Loss: 0.6740, Accuracy: 54.63%, Precision: 55.81%\n",
      "Epoch: 0, Batch: 208, Loss: 0.6996, Accuracy: 54.60%, Precision: 55.75%\n",
      "Epoch: 0, Batch: 209, Loss: 0.6482, Accuracy: 54.61%, Precision: 55.77%\n",
      "Epoch: 0, Batch: 210, Loss: 0.6860, Accuracy: 54.60%, Precision: 55.73%\n",
      "Epoch: 0, Batch: 211, Loss: 0.6397, Accuracy: 54.67%, Precision: 55.83%\n",
      "Epoch: 0, Batch: 212, Loss: 0.6205, Accuracy: 54.75%, Precision: 55.94%\n",
      "Epoch: 0, Batch: 213, Loss: 0.6459, Accuracy: 54.77%, Precision: 55.97%\n",
      "Epoch: 0, Batch: 214, Loss: 0.6762, Accuracy: 54.78%, Precision: 55.93%\n",
      "Epoch: 0, Batch: 215, Loss: 0.6614, Accuracy: 54.80%, Precision: 55.96%\n",
      "Epoch: 0, Batch: 216, Loss: 0.6646, Accuracy: 54.80%, Precision: 55.94%\n",
      "Epoch: 0, Batch: 217, Loss: 0.6654, Accuracy: 54.84%, Precision: 55.94%\n",
      "Epoch: 0, Batch: 218, Loss: 0.6145, Accuracy: 54.89%, Precision: 56.04%\n",
      "Epoch: 0, Batch: 219, Loss: 0.6657, Accuracy: 54.85%, Precision: 55.98%\n",
      "Epoch: 0, Batch: 220, Loss: 0.6868, Accuracy: 54.87%, Precision: 55.99%\n",
      "Epoch: 0, Batch: 221, Loss: 0.6926, Accuracy: 54.88%, Precision: 55.97%\n",
      "Epoch: 0, Batch: 222, Loss: 0.6324, Accuracy: 54.88%, Precision: 55.92%\n",
      "Epoch: 0, Batch: 223, Loss: 0.6662, Accuracy: 54.89%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 224, Loss: 0.6634, Accuracy: 54.90%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 225, Loss: 0.6586, Accuracy: 54.89%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 226, Loss: 0.5887, Accuracy: 54.95%, Precision: 55.93%\n",
      "Epoch: 0, Batch: 227, Loss: 1.0054, Accuracy: 54.97%, Precision: 56.03%\n",
      "Epoch: 0, Batch: 228, Loss: 0.6658, Accuracy: 54.95%, Precision: 55.96%\n",
      "Epoch: 0, Batch: 229, Loss: 0.6399, Accuracy: 54.95%, Precision: 56.00%\n",
      "Epoch: 0, Batch: 230, Loss: 0.6412, Accuracy: 54.95%, Precision: 55.94%\n",
      "Epoch: 0, Batch: 231, Loss: 0.6208, Accuracy: 54.99%, Precision: 55.96%\n",
      "Epoch: 0, Batch: 232, Loss: 0.6911, Accuracy: 54.97%, Precision: 55.82%\n",
      "Epoch: 0, Batch: 233, Loss: 0.6851, Accuracy: 54.99%, Precision: 55.85%\n",
      "Epoch: 0, Batch: 234, Loss: 0.6563, Accuracy: 55.02%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 235, Loss: 0.6760, Accuracy: 54.97%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 236, Loss: 0.6262, Accuracy: 54.97%, Precision: 55.78%\n",
      "Epoch: 0, Batch: 237, Loss: 0.6486, Accuracy: 54.94%, Precision: 55.79%\n",
      "Epoch: 0, Batch: 238, Loss: 0.6277, Accuracy: 54.98%, Precision: 55.79%\n",
      "Epoch: 0, Batch: 239, Loss: 0.7386, Accuracy: 54.99%, Precision: 55.79%\n",
      "Epoch: 0, Batch: 240, Loss: 0.6844, Accuracy: 55.00%, Precision: 55.77%\n",
      "Epoch: 0, Batch: 241, Loss: 0.6680, Accuracy: 54.99%, Precision: 55.75%\n",
      "Epoch: 0, Batch: 242, Loss: 0.6193, Accuracy: 55.04%, Precision: 55.76%\n",
      "Epoch: 0, Batch: 243, Loss: 0.6904, Accuracy: 54.99%, Precision: 55.75%\n",
      "Epoch: 0, Batch: 244, Loss: 0.6751, Accuracy: 54.94%, Precision: 55.71%\n",
      "Epoch: 0, Batch: 245, Loss: 0.6360, Accuracy: 55.00%, Precision: 55.77%\n",
      "Epoch: 0, Batch: 246, Loss: 0.6404, Accuracy: 55.06%, Precision: 55.83%\n",
      "Epoch: 0, Batch: 247, Loss: 0.6562, Accuracy: 55.10%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 248, Loss: 0.6988, Accuracy: 55.00%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 249, Loss: 0.6028, Accuracy: 55.06%, Precision: 55.88%\n",
      "Epoch: 0, Batch: 250, Loss: 0.6724, Accuracy: 54.99%, Precision: 55.77%\n",
      "Epoch: 0, Batch: 251, Loss: 0.6415, Accuracy: 55.02%, Precision: 55.77%\n",
      "Epoch: 0, Batch: 252, Loss: 0.5818, Accuracy: 55.11%, Precision: 55.77%\n",
      "Epoch: 0, Batch: 253, Loss: 0.6217, Accuracy: 55.18%, Precision: 55.87%\n",
      "Epoch: 0, Batch: 254, Loss: 0.6677, Accuracy: 55.16%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 255, Loss: 0.6050, Accuracy: 55.16%, Precision: 55.82%\n",
      "Epoch: 0, Batch: 256, Loss: 0.6220, Accuracy: 55.16%, Precision: 55.83%\n",
      "Epoch: 0, Batch: 257, Loss: 0.5393, Accuracy: 55.24%, Precision: 55.91%\n",
      "Epoch: 0, Batch: 258, Loss: 0.6991, Accuracy: 55.27%, Precision: 55.91%\n",
      "Epoch: 0, Batch: 259, Loss: 0.6400, Accuracy: 55.30%, Precision: 55.93%\n",
      "Epoch: 0, Batch: 260, Loss: 0.6061, Accuracy: 55.31%, Precision: 55.92%\n",
      "Epoch: 0, Batch: 261, Loss: 0.6905, Accuracy: 55.28%, Precision: 55.85%\n",
      "Epoch: 0, Batch: 262, Loss: 0.6986, Accuracy: 55.30%, Precision: 55.83%\n",
      "Epoch: 0, Batch: 263, Loss: 0.8966, Accuracy: 55.25%, Precision: 55.80%\n",
      "Epoch: 0, Batch: 264, Loss: 0.9162, Accuracy: 55.24%, Precision: 55.87%\n",
      "Epoch: 0, Batch: 265, Loss: 0.6273, Accuracy: 55.28%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 266, Loss: 0.6596, Accuracy: 55.29%, Precision: 55.90%\n",
      "Epoch: 0, Batch: 267, Loss: 0.6414, Accuracy: 55.30%, Precision: 55.92%\n",
      "Epoch: 0, Batch: 268, Loss: 0.6833, Accuracy: 55.28%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 269, Loss: 0.6539, Accuracy: 55.29%, Precision: 55.87%\n",
      "Epoch: 0, Batch: 270, Loss: 0.6894, Accuracy: 55.28%, Precision: 55.82%\n",
      "Epoch: 0, Batch: 271, Loss: 0.6603, Accuracy: 55.28%, Precision: 55.78%\n",
      "Epoch: 0, Batch: 272, Loss: 0.6475, Accuracy: 55.33%, Precision: 55.81%\n",
      "Epoch: 0, Batch: 273, Loss: 0.6649, Accuracy: 55.36%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 274, Loss: 0.6944, Accuracy: 55.34%, Precision: 55.83%\n",
      "Epoch: 0, Batch: 275, Loss: 0.7079, Accuracy: 55.32%, Precision: 55.78%\n",
      "Epoch: 0, Batch: 276, Loss: 0.6644, Accuracy: 55.34%, Precision: 55.80%\n",
      "Epoch: 0, Batch: 277, Loss: 0.6857, Accuracy: 55.32%, Precision: 55.73%\n",
      "Epoch: 0, Batch: 278, Loss: 0.6679, Accuracy: 55.33%, Precision: 55.71%\n",
      "Epoch: 0, Batch: 279, Loss: 0.6256, Accuracy: 55.40%, Precision: 55.80%\n",
      "Epoch: 0, Batch: 280, Loss: 0.6404, Accuracy: 55.45%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 281, Loss: 0.6330, Accuracy: 55.45%, Precision: 55.91%\n",
      "Epoch: 0, Batch: 282, Loss: 0.6617, Accuracy: 55.45%, Precision: 55.88%\n",
      "Epoch: 0, Batch: 283, Loss: 0.6487, Accuracy: 55.48%, Precision: 55.85%\n",
      "Epoch: 0, Batch: 284, Loss: 0.6842, Accuracy: 55.49%, Precision: 55.92%\n",
      "Epoch: 0, Batch: 285, Loss: 0.7099, Accuracy: 55.46%, Precision: 55.87%\n",
      "Epoch: 0, Batch: 286, Loss: 0.6692, Accuracy: 55.45%, Precision: 55.86%\n",
      "Epoch: 0, Batch: 287, Loss: 0.6539, Accuracy: 55.49%, Precision: 55.91%\n",
      "Epoch: 0, Batch: 288, Loss: 0.7199, Accuracy: 55.45%, Precision: 55.87%\n",
      "Epoch: 0, Batch: 289, Loss: 0.6981, Accuracy: 55.41%, Precision: 55.78%\n",
      "Epoch: 0, Batch: 290, Loss: 0.6054, Accuracy: 55.45%, Precision: 55.82%\n",
      "Epoch: 0, Batch: 291, Loss: 0.6814, Accuracy: 55.46%, Precision: 55.82%\n",
      "Epoch: 0, Batch: 292, Loss: 0.6725, Accuracy: 55.44%, Precision: 55.78%\n",
      "Epoch: 0, Batch: 293, Loss: 0.6050, Accuracy: 55.46%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 294, Loss: 0.6722, Accuracy: 55.45%, Precision: 55.84%\n",
      "Epoch: 0, Batch: 295, Loss: 0.6055, Accuracy: 55.52%, Precision: 55.89%\n",
      "Epoch: 0, Batch: 296, Loss: 0.6157, Accuracy: 55.55%, Precision: 55.93%\n",
      "Epoch: 0, Batch: 297, Loss: 0.6220, Accuracy: 55.62%, Precision: 56.00%\n",
      "Epoch: 0, Batch: 298, Loss: 0.5945, Accuracy: 55.67%, Precision: 56.08%\n",
      "Epoch: 0, Batch: 299, Loss: 0.6615, Accuracy: 55.68%, Precision: 56.05%\n",
      "Epoch: 0, Batch: 300, Loss: 0.7408, Accuracy: 55.64%, Precision: 56.05%\n",
      "Epoch: 0, Batch: 301, Loss: 0.5782, Accuracy: 55.70%, Precision: 56.13%\n",
      "Epoch: 0, Batch: 302, Loss: 0.6846, Accuracy: 55.68%, Precision: 56.13%\n",
      "Epoch: 0, Batch: 303, Loss: 0.5954, Accuracy: 55.73%, Precision: 56.17%\n",
      "Epoch: 0, Batch: 304, Loss: 0.7325, Accuracy: 55.76%, Precision: 56.21%\n",
      "Epoch: 0, Batch: 305, Loss: 0.8211, Accuracy: 55.72%, Precision: 56.16%\n",
      "Epoch: 0, Batch: 306, Loss: 0.6858, Accuracy: 55.71%, Precision: 56.16%\n",
      "Epoch: 0, Batch: 307, Loss: 0.7258, Accuracy: 55.71%, Precision: 56.13%\n",
      "Epoch: 0, Batch: 308, Loss: 0.5643, Accuracy: 55.76%, Precision: 56.20%\n",
      "Epoch: 0, Batch: 309, Loss: 0.6688, Accuracy: 55.78%, Precision: 56.28%\n",
      "Epoch: 0, Batch: 310, Loss: 0.6711, Accuracy: 55.78%, Precision: 56.24%\n",
      "Epoch: 0, Batch: 311, Loss: 0.7163, Accuracy: 55.80%, Precision: 56.24%\n",
      "Epoch: 0, Batch: 312, Loss: 0.6722, Accuracy: 55.78%, Precision: 56.22%\n",
      "Epoch: 0, Batch: 313, Loss: 0.6595, Accuracy: 55.77%, Precision: 56.19%\n",
      "Epoch: 0, Batch: 314, Loss: 0.5818, Accuracy: 55.84%, Precision: 56.30%\n",
      "Epoch: 0, Batch: 315, Loss: 0.6271, Accuracy: 55.84%, Precision: 56.29%\n",
      "Epoch: 0, Batch: 316, Loss: 0.6682, Accuracy: 55.84%, Precision: 56.32%\n",
      "Epoch: 0, Batch: 317, Loss: 0.6331, Accuracy: 55.85%, Precision: 56.32%\n",
      "Epoch: 0, Batch: 318, Loss: 0.6669, Accuracy: 55.86%, Precision: 56.31%\n",
      "Epoch: 0, Batch: 319, Loss: 0.6991, Accuracy: 55.82%, Precision: 56.20%\n",
      "Epoch: 0, Batch: 320, Loss: 0.6535, Accuracy: 55.83%, Precision: 56.23%\n",
      "Epoch: 0, Batch: 321, Loss: 0.6795, Accuracy: 55.80%, Precision: 56.20%\n",
      "Epoch: 0, Batch: 322, Loss: 0.7174, Accuracy: 55.77%, Precision: 56.17%\n",
      "Epoch: 0, Batch: 323, Loss: 0.7136, Accuracy: 55.77%, Precision: 56.18%\n",
      "Epoch: 0, Batch: 324, Loss: 0.6165, Accuracy: 55.77%, Precision: 56.20%\n",
      "Epoch: 0, Batch: 325, Loss: 0.6848, Accuracy: 55.78%, Precision: 56.22%\n",
      "Epoch: 0, Batch: 326, Loss: 0.6615, Accuracy: 55.76%, Precision: 56.22%\n",
      "Epoch: 0, Batch: 327, Loss: 0.6364, Accuracy: 55.77%, Precision: 56.23%\n",
      "Epoch: 0, Batch: 328, Loss: 0.6024, Accuracy: 55.83%, Precision: 56.26%\n",
      "Epoch: 0, Batch: 329, Loss: 0.6411, Accuracy: 55.83%, Precision: 56.25%\n",
      "Epoch: 0, Batch: 330, Loss: 0.6579, Accuracy: 55.82%, Precision: 56.24%\n",
      "Epoch: 0, Batch: 331, Loss: 0.6792, Accuracy: 55.83%, Precision: 56.26%\n",
      "Epoch: 0, Batch: 332, Loss: 0.6129, Accuracy: 55.85%, Precision: 56.30%\n",
      "Epoch: 0, Batch: 333, Loss: 0.6637, Accuracy: 55.87%, Precision: 56.32%\n",
      "Epoch: 0, Batch: 334, Loss: 0.6770, Accuracy: 55.84%, Precision: 56.28%\n",
      "Epoch: 0, Batch: 335, Loss: 0.6793, Accuracy: 55.79%, Precision: 56.20%\n",
      "Epoch: 0, Batch: 336, Loss: 0.6301, Accuracy: 55.82%, Precision: 56.26%\n",
      "Epoch: 0, Batch: 337, Loss: 0.6762, Accuracy: 55.81%, Precision: 56.22%\n",
      "Epoch: 0, Batch: 338, Loss: 0.6086, Accuracy: 55.83%, Precision: 56.23%\n",
      "Epoch: 0, Batch: 339, Loss: 0.5927, Accuracy: 55.87%, Precision: 56.27%\n",
      "Epoch: 0, Batch: 340, Loss: 0.6885, Accuracy: 55.85%, Precision: 56.23%\n",
      "Epoch: 0, Batch: 341, Loss: 0.6361, Accuracy: 55.86%, Precision: 56.23%\n",
      "Epoch: 0, Batch: 342, Loss: 0.6302, Accuracy: 55.87%, Precision: 56.21%\n",
      "Epoch: 0, Batch: 343, Loss: 0.6609, Accuracy: 55.83%, Precision: 56.22%\n",
      "Epoch: 0, Batch: 344, Loss: 0.6178, Accuracy: 55.87%, Precision: 56.25%\n",
      "Epoch: 0, Batch: 345, Loss: 0.5993, Accuracy: 55.92%, Precision: 56.32%\n",
      "Epoch: 0, Batch: 346, Loss: 0.6473, Accuracy: 55.92%, Precision: 56.27%\n",
      "Epoch: 0, Batch: 347, Loss: 0.6596, Accuracy: 55.93%, Precision: 56.25%\n",
      "Epoch: 0, Batch: 348, Loss: 0.7042, Accuracy: 55.93%, Precision: 56.24%\n",
      "Epoch: 0, Batch: 349, Loss: 0.7088, Accuracy: 55.91%, Precision: 56.20%\n",
      "Epoch: 0, Batch: 350, Loss: 0.5895, Accuracy: 55.96%, Precision: 56.26%\n",
      "Epoch: 0, Batch: 351, Loss: 0.6469, Accuracy: 55.96%, Precision: 56.24%\n",
      "Epoch: 0, Batch: 352, Loss: 0.6791, Accuracy: 55.97%, Precision: 56.25%\n",
      "Epoch: 0, Batch: 353, Loss: 0.6596, Accuracy: 55.97%, Precision: 56.22%\n",
      "Epoch: 0, Batch: 354, Loss: 0.6286, Accuracy: 55.96%, Precision: 56.24%\n",
      "Epoch: 0, Batch: 355, Loss: 0.6501, Accuracy: 55.94%, Precision: 56.27%\n",
      "Epoch: 0, Batch: 356, Loss: 0.6123, Accuracy: 55.96%, Precision: 56.29%\n",
      "Epoch: 0, Batch: 357, Loss: 0.6502, Accuracy: 55.97%, Precision: 56.31%\n",
      "Epoch: 0, Batch: 358, Loss: 0.6181, Accuracy: 56.03%, Precision: 56.35%\n",
      "Epoch: 0, Batch: 359, Loss: 0.6982, Accuracy: 56.05%, Precision: 56.36%\n",
      "Epoch: 0, Batch: 360, Loss: 0.6077, Accuracy: 56.06%, Precision: 56.37%\n",
      "Epoch: 0, Batch: 361, Loss: 0.6946, Accuracy: 56.04%, Precision: 56.33%\n",
      "Epoch: 0, Batch: 362, Loss: 0.6963, Accuracy: 56.07%, Precision: 56.37%\n",
      "Epoch: 0, Batch: 363, Loss: 0.6517, Accuracy: 56.08%, Precision: 56.36%\n",
      "Epoch: 0, Batch: 364, Loss: 0.5927, Accuracy: 56.09%, Precision: 56.35%\n",
      "Epoch: 0, Batch: 365, Loss: 0.5925, Accuracy: 56.10%, Precision: 56.38%\n",
      "Epoch: 0, Batch: 366, Loss: 0.7337, Accuracy: 56.11%, Precision: 56.40%\n",
      "Epoch: 0, Batch: 367, Loss: 0.6315, Accuracy: 56.12%, Precision: 56.38%\n",
      "Epoch: 0, Batch: 368, Loss: 0.5852, Accuracy: 56.16%, Precision: 56.41%\n",
      "Epoch: 0, Batch: 369, Loss: 0.6810, Accuracy: 56.16%, Precision: 56.41%\n",
      "Epoch: 0, Batch: 370, Loss: 1.0020, Accuracy: 56.14%, Precision: 56.37%\n",
      "Epoch: 0, Batch: 371, Loss: 0.6250, Accuracy: 56.18%, Precision: 56.42%\n",
      "Epoch: 0, Batch: 372, Loss: 0.5981, Accuracy: 56.21%, Precision: 56.44%\n",
      "Epoch: 0, Batch: 373, Loss: 0.6012, Accuracy: 56.22%, Precision: 56.49%\n",
      "Epoch: 0, Batch: 374, Loss: 0.6567, Accuracy: 56.24%, Precision: 56.50%\n",
      "Epoch: 0, Batch: 375, Loss: 0.5851, Accuracy: 56.30%, Precision: 56.56%\n",
      "Epoch: 0, Batch: 376, Loss: 0.6242, Accuracy: 56.33%, Precision: 56.59%\n",
      "Epoch: 0, Batch: 377, Loss: 0.6204, Accuracy: 56.35%, Precision: 56.62%\n",
      "Epoch: 0, Batch: 378, Loss: 0.7526, Accuracy: 56.30%, Precision: 56.52%\n",
      "Epoch: 0, Batch: 379, Loss: 0.6893, Accuracy: 56.32%, Precision: 56.50%\n",
      "Epoch: 0, Batch: 380, Loss: 0.6378, Accuracy: 56.33%, Precision: 56.51%\n",
      "Epoch: 0, Batch: 381, Loss: 0.6369, Accuracy: 56.36%, Precision: 56.56%\n",
      "Epoch: 0, Batch: 382, Loss: 0.6319, Accuracy: 56.37%, Precision: 56.54%\n",
      "Epoch: 0, Batch: 383, Loss: 0.5751, Accuracy: 56.41%, Precision: 56.55%\n",
      "Epoch: 0, Batch: 384, Loss: 0.7360, Accuracy: 56.37%, Precision: 56.53%\n",
      "Epoch: 0, Batch: 385, Loss: 0.6408, Accuracy: 56.40%, Precision: 56.56%\n",
      "Epoch: 0, Batch: 386, Loss: 0.6283, Accuracy: 56.39%, Precision: 56.58%\n",
      "Epoch: 0, Batch: 387, Loss: 0.6695, Accuracy: 56.39%, Precision: 56.60%\n",
      "Epoch: 0, Batch: 388, Loss: 0.6350, Accuracy: 56.42%, Precision: 56.63%\n",
      "Epoch: 0, Batch: 389, Loss: 0.6334, Accuracy: 56.46%, Precision: 56.69%\n",
      "Epoch: 0, Batch: 390, Loss: 0.6629, Accuracy: 56.44%, Precision: 56.67%\n",
      "Epoch: 0, Batch: 391, Loss: 0.6683, Accuracy: 56.42%, Precision: 56.65%\n",
      "Epoch: 0, Batch: 392, Loss: 0.6720, Accuracy: 56.44%, Precision: 56.66%\n",
      "Epoch: 0, Batch: 393, Loss: 0.6648, Accuracy: 56.42%, Precision: 56.68%\n",
      "Epoch: 0, Batch: 394, Loss: 0.6575, Accuracy: 56.46%, Precision: 56.74%\n",
      "Epoch: 0, Batch: 395, Loss: 0.6074, Accuracy: 56.49%, Precision: 56.76%\n",
      "Epoch: 0, Batch: 396, Loss: 0.5890, Accuracy: 56.53%, Precision: 56.82%\n",
      "Epoch: 0, Batch: 397, Loss: 0.6474, Accuracy: 56.53%, Precision: 56.78%\n",
      "Epoch: 0, Batch: 398, Loss: 0.6552, Accuracy: 56.52%, Precision: 56.76%\n",
      "Epoch: 0, Batch: 399, Loss: 0.6663, Accuracy: 56.56%, Precision: 56.77%\n",
      "Epoch: 0, Batch: 400, Loss: 0.5902, Accuracy: 56.57%, Precision: 56.79%\n",
      "Epoch: 0, Batch: 401, Loss: 0.6329, Accuracy: 56.57%, Precision: 56.78%\n",
      "Epoch: 0, Batch: 402, Loss: 0.5572, Accuracy: 56.59%, Precision: 56.79%\n",
      "Epoch: 0, Batch: 403, Loss: 0.7051, Accuracy: 56.59%, Precision: 56.76%\n",
      "Epoch: 0, Batch: 404, Loss: 0.5968, Accuracy: 56.62%, Precision: 56.80%\n",
      "Epoch: 0, Batch: 405, Loss: 0.5016, Accuracy: 56.65%, Precision: 56.83%\n",
      "Epoch: 0, Batch: 406, Loss: 0.5904, Accuracy: 56.67%, Precision: 56.85%\n",
      "Epoch: 0, Batch: 407, Loss: 0.6758, Accuracy: 56.67%, Precision: 56.85%\n",
      "Epoch: 0, Batch: 408, Loss: 0.8348, Accuracy: 56.65%, Precision: 56.83%\n",
      "Epoch: 0, Batch: 409, Loss: 0.6686, Accuracy: 56.68%, Precision: 56.85%\n",
      "Epoch: 0, Batch: 410, Loss: 0.6013, Accuracy: 56.71%, Precision: 56.88%\n",
      "Epoch: 0, Batch: 411, Loss: 0.6525, Accuracy: 56.71%, Precision: 56.88%\n",
      "Epoch: 0, Batch: 412, Loss: 0.5738, Accuracy: 56.75%, Precision: 56.92%\n",
      "Epoch: 0, Batch: 413, Loss: 0.5999, Accuracy: 56.78%, Precision: 56.96%\n",
      "Epoch: 0, Batch: 414, Loss: 0.6492, Accuracy: 56.79%, Precision: 56.97%\n",
      "Epoch: 0, Batch: 415, Loss: 0.6152, Accuracy: 56.81%, Precision: 57.02%\n",
      "Epoch: 0, Batch: 416, Loss: 0.6518, Accuracy: 56.81%, Precision: 57.01%\n",
      "Epoch: 0, Batch: 417, Loss: 0.6087, Accuracy: 56.83%, Precision: 57.05%\n",
      "Epoch: 0, Batch: 418, Loss: 0.7046, Accuracy: 56.83%, Precision: 57.02%\n",
      "Epoch: 0, Batch: 419, Loss: 0.6542, Accuracy: 56.82%, Precision: 57.04%\n",
      "Epoch: 0, Batch: 420, Loss: 0.6129, Accuracy: 56.84%, Precision: 57.04%\n",
      "Epoch: 0, Batch: 421, Loss: 0.5838, Accuracy: 56.85%, Precision: 57.06%\n",
      "Epoch: 0, Batch: 422, Loss: 0.6407, Accuracy: 56.84%, Precision: 57.04%\n",
      "Epoch: 0, Batch: 423, Loss: 0.7295, Accuracy: 56.83%, Precision: 57.04%\n",
      "Epoch: 0, Batch: 424, Loss: 0.6773, Accuracy: 56.82%, Precision: 57.05%\n",
      "Epoch: 0, Batch: 425, Loss: 0.6473, Accuracy: 56.79%, Precision: 56.99%\n",
      "Epoch: 0, Batch: 426, Loss: 0.6485, Accuracy: 56.79%, Precision: 57.02%\n",
      "Epoch: 0, Batch: 427, Loss: 0.5668, Accuracy: 56.83%, Precision: 57.07%\n",
      "Epoch: 0, Batch: 428, Loss: 0.6798, Accuracy: 56.86%, Precision: 57.11%\n",
      "Epoch: 0, Batch: 429, Loss: 0.6172, Accuracy: 56.89%, Precision: 57.14%\n",
      "Epoch: 0, Batch: 430, Loss: 0.6061, Accuracy: 56.90%, Precision: 57.17%\n",
      "Epoch: 0, Batch: 431, Loss: 0.5711, Accuracy: 56.94%, Precision: 57.22%\n",
      "Epoch: 0, Batch: 432, Loss: 0.7158, Accuracy: 56.90%, Precision: 57.15%\n",
      "Epoch: 0, Batch: 433, Loss: 0.5633, Accuracy: 56.92%, Precision: 57.17%\n",
      "Epoch: 0, Batch: 434, Loss: 0.6323, Accuracy: 56.93%, Precision: 57.15%\n",
      "Epoch: 0, Batch: 435, Loss: 0.6549, Accuracy: 56.92%, Precision: 57.11%\n",
      "Epoch: 0, Batch: 436, Loss: 0.5900, Accuracy: 56.94%, Precision: 57.14%\n",
      "Epoch: 0, Batch: 437, Loss: 0.6034, Accuracy: 56.97%, Precision: 57.16%\n",
      "Epoch: 0, Batch: 438, Loss: 0.5859, Accuracy: 57.01%, Precision: 57.16%\n",
      "Epoch: 0, Batch: 439, Loss: 0.6335, Accuracy: 57.02%, Precision: 57.16%\n",
      "Epoch: 0, Batch: 440, Loss: 0.7737, Accuracy: 56.97%, Precision: 57.16%\n",
      "Epoch: 0, Batch: 441, Loss: 0.6259, Accuracy: 56.97%, Precision: 57.17%\n",
      "Epoch: 0, Batch: 442, Loss: 0.6044, Accuracy: 56.99%, Precision: 57.19%\n",
      "Epoch: 0, Batch: 443, Loss: 0.6343, Accuracy: 56.96%, Precision: 57.16%\n",
      "Epoch: 0, Batch: 444, Loss: 0.6452, Accuracy: 56.95%, Precision: 57.14%\n",
      "Epoch: 0, Batch: 445, Loss: 0.6555, Accuracy: 56.93%, Precision: 57.15%\n",
      "Epoch: 0, Batch: 446, Loss: 0.6320, Accuracy: 56.96%, Precision: 57.17%\n",
      "Epoch: 0, Batch: 447, Loss: 0.6068, Accuracy: 56.98%, Precision: 57.21%\n",
      "Epoch: 0, Batch: 448, Loss: 0.6428, Accuracy: 56.94%, Precision: 57.18%\n",
      "Epoch: 0, Batch: 449, Loss: 0.7910, Accuracy: 56.96%, Precision: 57.22%\n",
      "Epoch: 0, Batch: 450, Loss: 0.7124, Accuracy: 56.99%, Precision: 57.25%\n",
      "Epoch: 0, Batch: 451, Loss: 0.6593, Accuracy: 56.98%, Precision: 57.23%\n",
      "Epoch: 0, Batch: 452, Loss: 0.6301, Accuracy: 56.99%, Precision: 57.25%\n",
      "Epoch: 0, Batch: 453, Loss: 0.6492, Accuracy: 57.00%, Precision: 57.24%\n",
      "Epoch: 0, Batch: 454, Loss: 0.6622, Accuracy: 56.97%, Precision: 57.21%\n",
      "Epoch: 0, Batch: 455, Loss: 0.7092, Accuracy: 56.96%, Precision: 57.22%\n",
      "Epoch: 0, Batch: 456, Loss: 0.6104, Accuracy: 56.98%, Precision: 57.21%\n",
      "Epoch: 0, Batch: 457, Loss: 0.5705, Accuracy: 57.01%, Precision: 57.23%\n",
      "Epoch: 0, Batch: 458, Loss: 0.6832, Accuracy: 57.00%, Precision: 57.19%\n",
      "Epoch: 0, Batch: 459, Loss: 0.6301, Accuracy: 57.00%, Precision: 57.20%\n",
      "Epoch: 0, Batch: 460, Loss: 0.6522, Accuracy: 56.98%, Precision: 57.15%\n",
      "Epoch: 0, Batch: 461, Loss: 0.6552, Accuracy: 56.99%, Precision: 57.14%\n",
      "Epoch: 0, Batch: 462, Loss: 0.6305, Accuracy: 57.01%, Precision: 57.20%\n",
      "Epoch: 0, Batch: 463, Loss: 0.6873, Accuracy: 57.01%, Precision: 57.18%\n",
      "Epoch: 0, Batch: 464, Loss: 0.6712, Accuracy: 56.99%, Precision: 57.19%\n",
      "Epoch: 0, Batch: 465, Loss: 0.6261, Accuracy: 57.00%, Precision: 57.20%\n",
      "Epoch: 0, Batch: 466, Loss: 0.6521, Accuracy: 57.02%, Precision: 57.23%\n",
      "Epoch: 0, Batch: 467, Loss: 0.6769, Accuracy: 57.01%, Precision: 57.22%\n",
      "Epoch: 0, Batch: 468, Loss: 0.6107, Accuracy: 57.04%, Precision: 57.29%\n",
      "Epoch: 0, Batch: 469, Loss: 0.6441, Accuracy: 57.06%, Precision: 57.32%\n",
      "Epoch: 0, Batch: 470, Loss: 0.6659, Accuracy: 57.09%, Precision: 57.36%\n",
      "Epoch: 0, Batch: 471, Loss: 0.6454, Accuracy: 57.09%, Precision: 57.37%\n",
      "Epoch: 0, Batch: 472, Loss: 0.6633, Accuracy: 57.11%, Precision: 57.39%\n",
      "Epoch: 0, Batch: 473, Loss: 0.6391, Accuracy: 57.12%, Precision: 57.41%\n",
      "Epoch: 0, Batch: 474, Loss: 0.7509, Accuracy: 57.10%, Precision: 57.38%\n",
      "Epoch: 0, Batch: 475, Loss: 0.6131, Accuracy: 57.12%, Precision: 57.42%\n",
      "Epoch: 0, Batch: 476, Loss: 0.6063, Accuracy: 57.14%, Precision: 57.43%\n",
      "Epoch: 0, Batch: 477, Loss: 0.5466, Accuracy: 57.17%, Precision: 57.47%\n",
      "Epoch: 0, Batch: 478, Loss: 0.7737, Accuracy: 57.17%, Precision: 57.45%\n",
      "Epoch: 0, Batch: 479, Loss: 0.6381, Accuracy: 57.17%, Precision: 57.43%\n",
      "Epoch: 0, Batch: 480, Loss: 0.6295, Accuracy: 57.17%, Precision: 57.43%\n",
      "Epoch: 0, Batch: 481, Loss: 0.6724, Accuracy: 57.18%, Precision: 57.45%\n",
      "Epoch: 0, Batch: 482, Loss: 0.6151, Accuracy: 57.21%, Precision: 57.46%\n",
      "Epoch: 0, Batch: 483, Loss: 0.6358, Accuracy: 57.23%, Precision: 57.47%\n",
      "Epoch: 0, Batch: 484, Loss: 0.6436, Accuracy: 57.25%, Precision: 57.50%\n",
      "Epoch: 0, Batch: 485, Loss: 0.6388, Accuracy: 57.26%, Precision: 57.48%\n",
      "Epoch: 0, Batch: 486, Loss: 0.6207, Accuracy: 57.26%, Precision: 57.49%\n",
      "Epoch: 0, Batch: 487, Loss: 0.6117, Accuracy: 57.28%, Precision: 57.50%\n",
      "Epoch: 0, Batch: 488, Loss: 0.6038, Accuracy: 57.29%, Precision: 57.49%\n",
      "Epoch: 0, Batch: 489, Loss: 0.6524, Accuracy: 57.28%, Precision: 57.51%\n",
      "Epoch: 0, Batch: 490, Loss: 0.6468, Accuracy: 57.26%, Precision: 57.49%\n",
      "Epoch: 0, Batch: 491, Loss: 0.5530, Accuracy: 57.31%, Precision: 57.53%\n",
      "Epoch: 0, Batch: 492, Loss: 0.7081, Accuracy: 57.28%, Precision: 57.50%\n",
      "Epoch: 0, Batch: 493, Loss: 0.7483, Accuracy: 57.27%, Precision: 57.47%\n",
      "Epoch: 0, Batch: 494, Loss: 0.7199, Accuracy: 57.27%, Precision: 57.47%\n",
      "Epoch: 0, Batch: 495, Loss: 0.6252, Accuracy: 57.27%, Precision: 57.48%\n",
      "Epoch: 0, Batch: 496, Loss: 0.5284, Accuracy: 57.30%, Precision: 57.51%\n",
      "Epoch: 0, Batch: 497, Loss: 0.7652, Accuracy: 57.26%, Precision: 57.47%\n",
      "Epoch: 0, Batch: 498, Loss: 0.6088, Accuracy: 57.28%, Precision: 57.47%\n",
      "Epoch: 0, Batch: 499, Loss: 0.6437, Accuracy: 57.26%, Precision: 57.48%\n",
      "Epoch: 0, Batch: 500, Loss: 0.6548, Accuracy: 57.25%, Precision: 57.46%\n",
      "Epoch: 0, Batch: 501, Loss: 0.6176, Accuracy: 57.24%, Precision: 57.44%\n",
      "Epoch: 0, Batch: 502, Loss: 0.6044, Accuracy: 57.23%, Precision: 57.42%\n",
      "Epoch: 0, Batch: 503, Loss: 0.6600, Accuracy: 57.24%, Precision: 57.43%\n",
      "Epoch: 0, Batch: 504, Loss: 0.5801, Accuracy: 57.27%, Precision: 57.45%\n",
      "Epoch: 0, Batch: 505, Loss: 0.6518, Accuracy: 57.28%, Precision: 57.48%\n",
      "Epoch: 0, Batch: 506, Loss: 0.6008, Accuracy: 57.31%, Precision: 57.48%\n",
      "Epoch: 0, Batch: 507, Loss: 0.7026, Accuracy: 57.26%, Precision: 57.46%\n",
      "Epoch: 0, Batch: 508, Loss: 0.5358, Accuracy: 57.28%, Precision: 57.46%\n",
      "Epoch: 0, Batch: 509, Loss: 0.5318, Accuracy: 57.28%, Precision: 57.47%\n",
      "Epoch: 0, Batch: 510, Loss: 0.6731, Accuracy: 57.26%, Precision: 57.45%\n",
      "Epoch: 0, Batch: 511, Loss: 0.6097, Accuracy: 57.30%, Precision: 57.50%\n",
      "Epoch: 0, Batch: 512, Loss: 0.6493, Accuracy: 57.31%, Precision: 57.51%\n",
      "Epoch: 0, Batch: 513, Loss: 0.6661, Accuracy: 57.30%, Precision: 57.51%\n",
      "Epoch: 0, Batch: 514, Loss: 0.5857, Accuracy: 57.31%, Precision: 57.51%\n",
      "Epoch: 0, Batch: 515, Loss: 0.6118, Accuracy: 57.30%, Precision: 57.49%\n",
      "Epoch: 0, Batch: 516, Loss: 0.7775, Accuracy: 57.29%, Precision: 57.46%\n",
      "Epoch: 0, Batch: 517, Loss: 0.6607, Accuracy: 57.28%, Precision: 57.43%\n",
      "Epoch: 0, Batch: 518, Loss: 0.6405, Accuracy: 57.30%, Precision: 57.44%\n",
      "Epoch: 0, Batch: 519, Loss: 0.6024, Accuracy: 57.27%, Precision: 57.43%\n",
      "Epoch: 0, Batch: 520, Loss: 0.6341, Accuracy: 57.29%, Precision: 57.42%\n",
      "Epoch: 0, Batch: 521, Loss: 0.6285, Accuracy: 57.31%, Precision: 57.44%\n",
      "Epoch: 0, Batch: 522, Loss: 0.6784, Accuracy: 57.30%, Precision: 57.43%\n",
      "Epoch: 0, Batch: 523, Loss: 0.6722, Accuracy: 57.30%, Precision: 57.42%\n",
      "Epoch: 0, Batch: 524, Loss: 0.6415, Accuracy: 57.31%, Precision: 57.45%\n",
      "Epoch: 0, Batch: 525, Loss: 0.7069, Accuracy: 57.30%, Precision: 57.47%\n",
      "Epoch: 0, Batch: 526, Loss: 0.6304, Accuracy: 57.31%, Precision: 57.49%\n",
      "Epoch: 0, Batch: 527, Loss: 0.6321, Accuracy: 57.29%, Precision: 57.46%\n",
      "Epoch: 0, Batch: 528, Loss: 0.6376, Accuracy: 57.33%, Precision: 57.52%\n",
      "Epoch: 0, Batch: 529, Loss: 0.5809, Accuracy: 57.35%, Precision: 57.53%\n",
      "Epoch: 0, Batch: 530, Loss: 0.6269, Accuracy: 57.38%, Precision: 57.58%\n",
      "Epoch: 0, Batch: 531, Loss: 0.5902, Accuracy: 57.40%, Precision: 57.60%\n",
      "Epoch: 0, Batch: 532, Loss: 0.5990, Accuracy: 57.42%, Precision: 57.61%\n",
      "Epoch: 0, Batch: 533, Loss: 0.6033, Accuracy: 57.45%, Precision: 57.64%\n",
      "Epoch: 0, Batch: 534, Loss: 0.5765, Accuracy: 57.47%, Precision: 57.66%\n",
      "Epoch: 0, Batch: 535, Loss: 0.6211, Accuracy: 57.48%, Precision: 57.64%\n",
      "Epoch: 0, Batch: 536, Loss: 0.6085, Accuracy: 57.49%, Precision: 57.65%\n",
      "Epoch: 0, Batch: 537, Loss: 0.6611, Accuracy: 57.49%, Precision: 57.64%\n",
      "Epoch: 0, Batch: 538, Loss: 0.6082, Accuracy: 57.48%, Precision: 57.60%\n",
      "Epoch: 0, Batch: 539, Loss: 0.6010, Accuracy: 57.48%, Precision: 57.58%\n",
      "Epoch: 0, Batch: 540, Loss: 0.8319, Accuracy: 57.48%, Precision: 57.58%\n",
      "Epoch: 0, Batch: 541, Loss: 0.6668, Accuracy: 57.46%, Precision: 57.55%\n",
      "Epoch: 0, Batch: 542, Loss: 0.5904, Accuracy: 57.48%, Precision: 57.55%\n",
      "Epoch: 0, Batch: 543, Loss: 0.6295, Accuracy: 57.47%, Precision: 57.52%\n",
      "Epoch: 0, Batch: 544, Loss: 0.5786, Accuracy: 57.50%, Precision: 57.52%\n",
      "Epoch: 0, Batch: 545, Loss: 0.5596, Accuracy: 57.51%, Precision: 57.54%\n",
      "Epoch: 0, Batch: 546, Loss: 0.5895, Accuracy: 57.51%, Precision: 57.55%\n",
      "Epoch: 0, Batch: 547, Loss: 0.6350, Accuracy: 57.52%, Precision: 57.55%\n",
      "Epoch: 0, Batch: 548, Loss: 0.6042, Accuracy: 57.55%, Precision: 57.61%\n",
      "Epoch: 0, Batch: 549, Loss: 0.6688, Accuracy: 57.55%, Precision: 57.61%\n",
      "Epoch: 0, Batch: 550, Loss: 0.6143, Accuracy: 57.57%, Precision: 57.64%\n",
      "Epoch: 0, Batch: 551, Loss: 0.5849, Accuracy: 57.59%, Precision: 57.64%\n",
      "Epoch: 0, Batch: 552, Loss: 0.6509, Accuracy: 57.61%, Precision: 57.65%\n",
      "Epoch: 0, Batch: 553, Loss: 0.6868, Accuracy: 57.64%, Precision: 57.69%\n",
      "Epoch: 0, Batch: 554, Loss: 0.6806, Accuracy: 57.63%, Precision: 57.68%\n",
      "Epoch: 0, Batch: 555, Loss: 0.5610, Accuracy: 57.62%, Precision: 57.67%\n",
      "Epoch: 0, Batch: 556, Loss: 0.6050, Accuracy: 57.63%, Precision: 57.67%\n",
      "Epoch: 0, Batch: 557, Loss: 0.6162, Accuracy: 57.66%, Precision: 57.71%\n",
      "Epoch: 0, Batch: 558, Loss: 0.6122, Accuracy: 57.69%, Precision: 57.74%\n",
      "Epoch: 0, Batch: 559, Loss: 0.5732, Accuracy: 57.74%, Precision: 57.78%\n",
      "Epoch: 0, Batch: 560, Loss: 0.5894, Accuracy: 57.77%, Precision: 57.82%\n",
      "Epoch: 0, Batch: 561, Loss: 0.6323, Accuracy: 57.77%, Precision: 57.82%\n",
      "Epoch: 0, Batch: 562, Loss: 0.7179, Accuracy: 57.73%, Precision: 57.78%\n",
      "Epoch: 0, Batch: 563, Loss: 0.5874, Accuracy: 57.76%, Precision: 57.80%\n",
      "Epoch: 0, Batch: 564, Loss: 0.7828, Accuracy: 57.76%, Precision: 57.80%\n",
      "Epoch: 0, Batch: 565, Loss: 0.6593, Accuracy: 57.74%, Precision: 57.75%\n",
      "Epoch: 0, Batch: 566, Loss: 0.5346, Accuracy: 57.76%, Precision: 57.76%\n",
      "Epoch: 0, Batch: 567, Loss: 0.6385, Accuracy: 57.76%, Precision: 57.74%\n",
      "Epoch: 0, Batch: 568, Loss: 0.6354, Accuracy: 57.77%, Precision: 57.75%\n",
      "Epoch: 0, Batch: 569, Loss: 0.7126, Accuracy: 57.74%, Precision: 57.73%\n",
      "Epoch: 0, Batch: 570, Loss: 0.6598, Accuracy: 57.71%, Precision: 57.71%\n",
      "Epoch: 0, Batch: 571, Loss: 0.6165, Accuracy: 57.72%, Precision: 57.73%\n",
      "Epoch: 0, Batch: 572, Loss: 0.6175, Accuracy: 57.73%, Precision: 57.73%\n",
      "Epoch: 0, Batch: 573, Loss: 0.6045, Accuracy: 57.74%, Precision: 57.72%\n",
      "Epoch: 0, Batch: 574, Loss: 0.6130, Accuracy: 57.74%, Precision: 57.74%\n",
      "Epoch: 0, Batch: 575, Loss: 0.6498, Accuracy: 57.73%, Precision: 57.72%\n",
      "Epoch: 0, Batch: 576, Loss: 0.6452, Accuracy: 57.71%, Precision: 57.69%\n",
      "Epoch: 0, Batch: 577, Loss: 0.6828, Accuracy: 57.71%, Precision: 57.68%\n",
      "Epoch: 0, Batch: 578, Loss: 0.6351, Accuracy: 57.69%, Precision: 57.68%\n",
      "Epoch: 0, Batch: 579, Loss: 0.6761, Accuracy: 57.68%, Precision: 57.64%\n",
      "Epoch: 0, Batch: 580, Loss: 0.8515, Accuracy: 57.67%, Precision: 57.65%\n",
      "Epoch: 0, Batch: 581, Loss: 0.6201, Accuracy: 57.68%, Precision: 57.68%\n",
      "Epoch: 0, Batch: 582, Loss: 0.6339, Accuracy: 57.69%, Precision: 57.72%\n",
      "Epoch: 0, Batch: 583, Loss: 0.7266, Accuracy: 57.65%, Precision: 57.66%\n",
      "Epoch: 0, Batch: 584, Loss: 0.6893, Accuracy: 57.65%, Precision: 57.67%\n",
      "Epoch: 0, Batch: 585, Loss: 0.6940, Accuracy: 57.63%, Precision: 57.67%\n",
      "Epoch: 0, Batch: 586, Loss: 0.6760, Accuracy: 57.61%, Precision: 57.65%\n",
      "Epoch: 0, Batch: 587, Loss: 0.6257, Accuracy: 57.62%, Precision: 57.66%\n",
      "Epoch: 0, Batch: 588, Loss: 0.6455, Accuracy: 57.62%, Precision: 57.67%\n",
      "Epoch: 0, Batch: 589, Loss: 0.6459, Accuracy: 57.63%, Precision: 57.70%\n",
      "Epoch: 0, Batch: 590, Loss: 0.8275, Accuracy: 57.62%, Precision: 57.69%\n",
      "Epoch: 0, Batch: 591, Loss: 0.6636, Accuracy: 57.60%, Precision: 57.69%\n",
      "Epoch: 0, Batch: 592, Loss: 0.6700, Accuracy: 57.58%, Precision: 57.69%\n",
      "Epoch: 0, Batch: 593, Loss: 0.6324, Accuracy: 57.59%, Precision: 57.70%\n",
      "Epoch: 0, Batch: 594, Loss: 0.6363, Accuracy: 57.61%, Precision: 57.74%\n",
      "Epoch: 0, Batch: 595, Loss: 0.6093, Accuracy: 57.63%, Precision: 57.75%\n",
      "Epoch: 0, Batch: 596, Loss: 0.6369, Accuracy: 57.62%, Precision: 57.76%\n",
      "Epoch: 0, Batch: 597, Loss: 0.6596, Accuracy: 57.63%, Precision: 57.77%\n",
      "Epoch: 0, Batch: 598, Loss: 0.6152, Accuracy: 57.65%, Precision: 57.76%\n",
      "Epoch: 0, Batch: 599, Loss: 0.5894, Accuracy: 57.67%, Precision: 57.80%\n",
      "Epoch: 0, Batch: 600, Loss: 0.5931, Accuracy: 57.70%, Precision: 57.82%\n",
      "Epoch: 0, Batch: 601, Loss: 0.6354, Accuracy: 57.71%, Precision: 57.81%\n",
      "Epoch: 0, Batch: 602, Loss: 0.7086, Accuracy: 57.69%, Precision: 57.78%\n",
      "Epoch: 0, Batch: 603, Loss: 0.6402, Accuracy: 57.70%, Precision: 57.80%\n",
      "Epoch: 0, Batch: 604, Loss: 0.5687, Accuracy: 57.73%, Precision: 57.84%\n",
      "Epoch: 0, Batch: 605, Loss: 0.6198, Accuracy: 57.74%, Precision: 57.84%\n",
      "Epoch: 0, Batch: 606, Loss: 0.6350, Accuracy: 57.75%, Precision: 57.87%\n",
      "Epoch: 0, Batch: 607, Loss: 0.7745, Accuracy: 57.73%, Precision: 57.83%\n",
      "Epoch: 0, Batch: 608, Loss: 0.6134, Accuracy: 57.76%, Precision: 57.83%\n",
      "Epoch: 0, Batch: 609, Loss: 0.5288, Accuracy: 57.76%, Precision: 57.84%\n",
      "Epoch: 1, Batch: 1, Loss: 0.5946, Accuracy: 57.78%, Precision: 57.85%\n",
      "Epoch: 1, Batch: 2, Loss: 0.7078, Accuracy: 57.78%, Precision: 57.83%\n",
      "Epoch: 1, Batch: 3, Loss: 0.6593, Accuracy: 57.78%, Precision: 57.82%\n",
      "Epoch: 1, Batch: 4, Loss: 0.6256, Accuracy: 57.80%, Precision: 57.83%\n",
      "Epoch: 1, Batch: 5, Loss: 0.6504, Accuracy: 57.79%, Precision: 57.84%\n",
      "Epoch: 1, Batch: 6, Loss: 0.6829, Accuracy: 57.80%, Precision: 57.84%\n",
      "Epoch: 1, Batch: 7, Loss: 0.6589, Accuracy: 57.78%, Precision: 57.81%\n",
      "Epoch: 1, Batch: 8, Loss: 0.5918, Accuracy: 57.80%, Precision: 57.84%\n",
      "Epoch: 1, Batch: 9, Loss: 0.6094, Accuracy: 57.80%, Precision: 57.83%\n",
      "Epoch: 1, Batch: 10, Loss: 0.5973, Accuracy: 57.82%, Precision: 57.84%\n",
      "Epoch: 1, Batch: 11, Loss: 0.6095, Accuracy: 57.83%, Precision: 57.88%\n",
      "Epoch: 1, Batch: 12, Loss: 0.5770, Accuracy: 57.86%, Precision: 57.92%\n",
      "Epoch: 1, Batch: 13, Loss: 0.7357, Accuracy: 57.84%, Precision: 57.88%\n",
      "Epoch: 1, Batch: 14, Loss: 0.6171, Accuracy: 57.84%, Precision: 57.87%\n",
      "Epoch: 1, Batch: 15, Loss: 0.6894, Accuracy: 57.83%, Precision: 57.84%\n",
      "Epoch: 1, Batch: 16, Loss: 0.6311, Accuracy: 57.85%, Precision: 57.85%\n",
      "Epoch: 1, Batch: 17, Loss: 0.6115, Accuracy: 57.86%, Precision: 57.86%\n",
      "Epoch: 1, Batch: 18, Loss: 0.6301, Accuracy: 57.87%, Precision: 57.87%\n",
      "Epoch: 1, Batch: 19, Loss: 0.6108, Accuracy: 57.88%, Precision: 57.87%\n",
      "Epoch: 1, Batch: 20, Loss: 0.6489, Accuracy: 57.87%, Precision: 57.85%\n",
      "Epoch: 1, Batch: 21, Loss: 0.5768, Accuracy: 57.88%, Precision: 57.87%\n",
      "Epoch: 1, Batch: 22, Loss: 0.6747, Accuracy: 57.88%, Precision: 57.85%\n",
      "Epoch: 1, Batch: 23, Loss: 0.6352, Accuracy: 57.90%, Precision: 57.88%\n",
      "Epoch: 1, Batch: 24, Loss: 0.6027, Accuracy: 57.92%, Precision: 57.90%\n",
      "Epoch: 1, Batch: 25, Loss: 0.7387, Accuracy: 57.90%, Precision: 57.87%\n",
      "Epoch: 1, Batch: 26, Loss: 0.6375, Accuracy: 57.91%, Precision: 57.89%\n",
      "Epoch: 1, Batch: 27, Loss: 0.5274, Accuracy: 57.93%, Precision: 57.90%\n",
      "Epoch: 1, Batch: 28, Loss: 0.5629, Accuracy: 57.96%, Precision: 57.90%\n",
      "Epoch: 1, Batch: 29, Loss: 0.5510, Accuracy: 57.97%, Precision: 57.89%\n",
      "Epoch: 1, Batch: 30, Loss: 0.6911, Accuracy: 57.98%, Precision: 57.89%\n",
      "Epoch: 1, Batch: 31, Loss: 0.5984, Accuracy: 57.99%, Precision: 57.93%\n",
      "Epoch: 1, Batch: 32, Loss: 0.6987, Accuracy: 57.98%, Precision: 57.92%\n",
      "Epoch: 1, Batch: 33, Loss: 0.6264, Accuracy: 57.99%, Precision: 57.92%\n",
      "Epoch: 1, Batch: 34, Loss: 0.6332, Accuracy: 57.98%, Precision: 57.92%\n",
      "Epoch: 1, Batch: 35, Loss: 0.6987, Accuracy: 57.97%, Precision: 57.92%\n",
      "Epoch: 1, Batch: 36, Loss: 0.6022, Accuracy: 57.98%, Precision: 57.93%\n",
      "Epoch: 1, Batch: 37, Loss: 0.6999, Accuracy: 57.98%, Precision: 57.92%\n",
      "Epoch: 1, Batch: 38, Loss: 0.5849, Accuracy: 57.99%, Precision: 57.93%\n",
      "Epoch: 1, Batch: 39, Loss: 0.5857, Accuracy: 58.02%, Precision: 57.96%\n",
      "Epoch: 1, Batch: 40, Loss: 0.6937, Accuracy: 57.99%, Precision: 57.94%\n",
      "Epoch: 1, Batch: 41, Loss: 0.5786, Accuracy: 58.01%, Precision: 57.97%\n",
      "Epoch: 1, Batch: 42, Loss: 0.6496, Accuracy: 58.01%, Precision: 57.98%\n",
      "Epoch: 1, Batch: 43, Loss: 0.5175, Accuracy: 58.03%, Precision: 58.02%\n",
      "Epoch: 1, Batch: 44, Loss: 0.6684, Accuracy: 58.04%, Precision: 58.01%\n",
      "Epoch: 1, Batch: 45, Loss: 0.6839, Accuracy: 58.04%, Precision: 58.01%\n",
      "Epoch: 1, Batch: 46, Loss: 0.7038, Accuracy: 58.04%, Precision: 58.00%\n",
      "Epoch: 1, Batch: 47, Loss: 0.5856, Accuracy: 58.05%, Precision: 58.01%\n",
      "Epoch: 1, Batch: 48, Loss: 0.6079, Accuracy: 58.06%, Precision: 58.00%\n",
      "Epoch: 1, Batch: 49, Loss: 0.6277, Accuracy: 58.06%, Precision: 57.98%\n",
      "Epoch: 1, Batch: 50, Loss: 0.6185, Accuracy: 58.07%, Precision: 58.01%\n",
      "Epoch: 1, Batch: 51, Loss: 0.5880, Accuracy: 58.07%, Precision: 58.02%\n",
      "Epoch: 1, Batch: 52, Loss: 0.5866, Accuracy: 58.09%, Precision: 58.05%\n",
      "Epoch: 1, Batch: 53, Loss: 0.5235, Accuracy: 58.13%, Precision: 58.08%\n",
      "Epoch: 1, Batch: 54, Loss: 0.5591, Accuracy: 58.15%, Precision: 58.08%\n",
      "Epoch: 1, Batch: 55, Loss: 0.5584, Accuracy: 58.18%, Precision: 58.11%\n",
      "Epoch: 1, Batch: 56, Loss: 0.5234, Accuracy: 58.20%, Precision: 58.11%\n",
      "Epoch: 1, Batch: 57, Loss: 0.6935, Accuracy: 58.19%, Precision: 58.10%\n",
      "Epoch: 1, Batch: 58, Loss: 0.6755, Accuracy: 58.20%, Precision: 58.10%\n",
      "Epoch: 1, Batch: 59, Loss: 0.5631, Accuracy: 58.22%, Precision: 58.12%\n",
      "Epoch: 1, Batch: 60, Loss: 0.6470, Accuracy: 58.21%, Precision: 58.12%\n",
      "Epoch: 1, Batch: 61, Loss: 0.7712, Accuracy: 58.19%, Precision: 58.08%\n",
      "Epoch: 1, Batch: 62, Loss: 0.8499, Accuracy: 58.19%, Precision: 58.08%\n",
      "Epoch: 1, Batch: 63, Loss: 0.8497, Accuracy: 58.18%, Precision: 58.06%\n",
      "Epoch: 1, Batch: 64, Loss: 0.7612, Accuracy: 58.16%, Precision: 58.03%\n",
      "Epoch: 1, Batch: 65, Loss: 0.6015, Accuracy: 58.17%, Precision: 58.00%\n",
      "Epoch: 1, Batch: 66, Loss: 0.6463, Accuracy: 58.17%, Precision: 58.00%\n",
      "Epoch: 1, Batch: 67, Loss: 0.7021, Accuracy: 58.18%, Precision: 58.03%\n",
      "Epoch: 1, Batch: 68, Loss: 0.6487, Accuracy: 58.16%, Precision: 58.03%\n",
      "Epoch: 1, Batch: 69, Loss: 0.7191, Accuracy: 58.15%, Precision: 58.04%\n",
      "Epoch: 1, Batch: 70, Loss: 0.6738, Accuracy: 58.14%, Precision: 58.02%\n",
      "Epoch: 1, Batch: 71, Loss: 0.6298, Accuracy: 58.14%, Precision: 58.03%\n",
      "Epoch: 1, Batch: 72, Loss: 0.6430, Accuracy: 58.13%, Precision: 58.05%\n",
      "Epoch: 1, Batch: 73, Loss: 0.6394, Accuracy: 58.13%, Precision: 58.06%\n",
      "Epoch: 1, Batch: 74, Loss: 0.6479, Accuracy: 58.11%, Precision: 58.06%\n",
      "Epoch: 1, Batch: 75, Loss: 0.6476, Accuracy: 58.12%, Precision: 58.07%\n",
      "Epoch: 1, Batch: 76, Loss: 0.6723, Accuracy: 58.12%, Precision: 58.07%\n",
      "Epoch: 1, Batch: 77, Loss: 0.6607, Accuracy: 58.12%, Precision: 58.08%\n",
      "Epoch: 1, Batch: 78, Loss: 0.6491, Accuracy: 58.11%, Precision: 58.07%\n",
      "Epoch: 1, Batch: 79, Loss: 0.6542, Accuracy: 58.12%, Precision: 58.07%\n",
      "Epoch: 1, Batch: 80, Loss: 0.7022, Accuracy: 58.12%, Precision: 58.07%\n",
      "Epoch: 1, Batch: 81, Loss: 0.6564, Accuracy: 58.12%, Precision: 58.09%\n",
      "Epoch: 1, Batch: 82, Loss: 0.6763, Accuracy: 58.12%, Precision: 58.10%\n",
      "Epoch: 1, Batch: 83, Loss: 0.6316, Accuracy: 58.13%, Precision: 58.11%\n",
      "Epoch: 1, Batch: 84, Loss: 0.6182, Accuracy: 58.15%, Precision: 58.14%\n",
      "Epoch: 1, Batch: 85, Loss: 0.6570, Accuracy: 58.16%, Precision: 58.14%\n",
      "Epoch: 1, Batch: 86, Loss: 0.6251, Accuracy: 58.17%, Precision: 58.16%\n",
      "Epoch: 1, Batch: 87, Loss: 0.6275, Accuracy: 58.17%, Precision: 58.17%\n",
      "Epoch: 1, Batch: 88, Loss: 0.7391, Accuracy: 58.16%, Precision: 58.14%\n",
      "Epoch: 1, Batch: 89, Loss: 0.6886, Accuracy: 58.15%, Precision: 58.11%\n",
      "Epoch: 1, Batch: 90, Loss: 0.6498, Accuracy: 58.15%, Precision: 58.12%\n",
      "Epoch: 1, Batch: 91, Loss: 0.6791, Accuracy: 58.14%, Precision: 58.10%\n",
      "Epoch: 1, Batch: 92, Loss: 0.6077, Accuracy: 58.15%, Precision: 58.12%\n",
      "Epoch: 1, Batch: 93, Loss: 0.6261, Accuracy: 58.16%, Precision: 58.13%\n",
      "Epoch: 1, Batch: 94, Loss: 0.5945, Accuracy: 58.19%, Precision: 58.15%\n",
      "Epoch: 1, Batch: 95, Loss: 0.6248, Accuracy: 58.20%, Precision: 58.14%\n",
      "Epoch: 1, Batch: 96, Loss: 0.6194, Accuracy: 58.21%, Precision: 58.14%\n",
      "Epoch: 1, Batch: 97, Loss: 0.6840, Accuracy: 58.20%, Precision: 58.13%\n",
      "Epoch: 1, Batch: 98, Loss: 0.5808, Accuracy: 58.23%, Precision: 58.16%\n",
      "Epoch: 1, Batch: 99, Loss: 0.6291, Accuracy: 58.24%, Precision: 58.17%\n",
      "Epoch: 1, Batch: 100, Loss: 0.6100, Accuracy: 58.25%, Precision: 58.18%\n",
      "Epoch: 1, Batch: 101, Loss: 0.6692, Accuracy: 58.25%, Precision: 58.17%\n",
      "Epoch: 1, Batch: 102, Loss: 0.6377, Accuracy: 58.26%, Precision: 58.16%\n",
      "Epoch: 1, Batch: 103, Loss: 0.5648, Accuracy: 58.27%, Precision: 58.18%\n",
      "Epoch: 1, Batch: 104, Loss: 0.6614, Accuracy: 58.25%, Precision: 58.17%\n",
      "Epoch: 1, Batch: 105, Loss: 0.6746, Accuracy: 58.25%, Precision: 58.17%\n",
      "Epoch: 1, Batch: 106, Loss: 0.6493, Accuracy: 58.26%, Precision: 58.18%\n",
      "Epoch: 1, Batch: 107, Loss: 0.6265, Accuracy: 58.27%, Precision: 58.18%\n",
      "Epoch: 1, Batch: 108, Loss: 0.7205, Accuracy: 58.25%, Precision: 58.16%\n",
      "Epoch: 1, Batch: 109, Loss: 0.6869, Accuracy: 58.24%, Precision: 58.17%\n",
      "Epoch: 1, Batch: 110, Loss: 0.6295, Accuracy: 58.25%, Precision: 58.18%\n",
      "Epoch: 1, Batch: 111, Loss: 0.5727, Accuracy: 58.28%, Precision: 58.21%\n",
      "Epoch: 1, Batch: 112, Loss: 0.5999, Accuracy: 58.30%, Precision: 58.25%\n",
      "Epoch: 1, Batch: 113, Loss: 0.6662, Accuracy: 58.29%, Precision: 58.23%\n",
      "Epoch: 1, Batch: 114, Loss: 0.6234, Accuracy: 58.30%, Precision: 58.23%\n",
      "Epoch: 1, Batch: 115, Loss: 0.6664, Accuracy: 58.30%, Precision: 58.21%\n",
      "Epoch: 1, Batch: 116, Loss: 0.5869, Accuracy: 58.29%, Precision: 58.22%\n",
      "Epoch: 1, Batch: 117, Loss: 0.6385, Accuracy: 58.30%, Precision: 58.22%\n",
      "Epoch: 1, Batch: 118, Loss: 0.5606, Accuracy: 58.31%, Precision: 58.24%\n",
      "Epoch: 1, Batch: 119, Loss: 0.6170, Accuracy: 58.32%, Precision: 58.23%\n",
      "Epoch: 1, Batch: 120, Loss: 0.6179, Accuracy: 58.34%, Precision: 58.25%\n",
      "Epoch: 1, Batch: 121, Loss: 0.7545, Accuracy: 58.32%, Precision: 58.23%\n",
      "Epoch: 1, Batch: 122, Loss: 0.6611, Accuracy: 58.32%, Precision: 58.24%\n",
      "Epoch: 1, Batch: 123, Loss: 0.5285, Accuracy: 58.35%, Precision: 58.25%\n",
      "Epoch: 1, Batch: 124, Loss: 0.7205, Accuracy: 58.34%, Precision: 58.24%\n",
      "Epoch: 1, Batch: 125, Loss: 0.6350, Accuracy: 58.35%, Precision: 58.27%\n",
      "Epoch: 1, Batch: 126, Loss: 0.6017, Accuracy: 58.36%, Precision: 58.28%\n",
      "Epoch: 1, Batch: 127, Loss: 0.7372, Accuracy: 58.36%, Precision: 58.27%\n",
      "Epoch: 1, Batch: 128, Loss: 0.6064, Accuracy: 58.36%, Precision: 58.27%\n",
      "Epoch: 1, Batch: 129, Loss: 0.6000, Accuracy: 58.37%, Precision: 58.28%\n",
      "Epoch: 1, Batch: 130, Loss: 0.6068, Accuracy: 58.37%, Precision: 58.28%\n",
      "Epoch: 1, Batch: 131, Loss: 0.6541, Accuracy: 58.38%, Precision: 58.29%\n",
      "Epoch: 1, Batch: 132, Loss: 0.6064, Accuracy: 58.39%, Precision: 58.28%\n",
      "Epoch: 1, Batch: 133, Loss: 0.6154, Accuracy: 58.40%, Precision: 58.29%\n",
      "Epoch: 1, Batch: 134, Loss: 0.5969, Accuracy: 58.41%, Precision: 58.32%\n",
      "Epoch: 1, Batch: 135, Loss: 0.5774, Accuracy: 58.44%, Precision: 58.36%\n",
      "Epoch: 1, Batch: 136, Loss: 0.6021, Accuracy: 58.44%, Precision: 58.36%\n",
      "Epoch: 1, Batch: 137, Loss: 0.6884, Accuracy: 58.44%, Precision: 58.38%\n",
      "Epoch: 1, Batch: 138, Loss: 0.6657, Accuracy: 58.44%, Precision: 58.36%\n",
      "Epoch: 1, Batch: 139, Loss: 0.6867, Accuracy: 58.45%, Precision: 58.36%\n",
      "Epoch: 1, Batch: 140, Loss: 0.5474, Accuracy: 58.48%, Precision: 58.39%\n",
      "Epoch: 1, Batch: 141, Loss: 0.5825, Accuracy: 58.50%, Precision: 58.41%\n",
      "Epoch: 1, Batch: 142, Loss: 0.5819, Accuracy: 58.51%, Precision: 58.43%\n",
      "Epoch: 1, Batch: 143, Loss: 0.5055, Accuracy: 58.55%, Precision: 58.46%\n",
      "Epoch: 1, Batch: 144, Loss: 0.5727, Accuracy: 58.57%, Precision: 58.49%\n",
      "Epoch: 1, Batch: 145, Loss: 0.6338, Accuracy: 58.57%, Precision: 58.49%\n",
      "Epoch: 1, Batch: 146, Loss: 0.6502, Accuracy: 58.57%, Precision: 58.50%\n",
      "Epoch: 1, Batch: 147, Loss: 0.6323, Accuracy: 58.57%, Precision: 58.47%\n",
      "Epoch: 1, Batch: 148, Loss: 0.5158, Accuracy: 58.60%, Precision: 58.51%\n",
      "Epoch: 1, Batch: 149, Loss: 0.6006, Accuracy: 58.61%, Precision: 58.52%\n",
      "Epoch: 1, Batch: 150, Loss: 0.5238, Accuracy: 58.62%, Precision: 58.54%\n",
      "Epoch: 1, Batch: 151, Loss: 0.5079, Accuracy: 58.66%, Precision: 58.58%\n",
      "Epoch: 1, Batch: 152, Loss: 0.7614, Accuracy: 58.66%, Precision: 58.57%\n",
      "Epoch: 1, Batch: 153, Loss: 0.6128, Accuracy: 58.67%, Precision: 58.58%\n",
      "Epoch: 1, Batch: 154, Loss: 0.8026, Accuracy: 58.67%, Precision: 58.58%\n",
      "Epoch: 1, Batch: 155, Loss: 0.6647, Accuracy: 58.67%, Precision: 58.58%\n",
      "Epoch: 1, Batch: 156, Loss: 0.5340, Accuracy: 58.69%, Precision: 58.59%\n",
      "Epoch: 1, Batch: 157, Loss: 0.5436, Accuracy: 58.71%, Precision: 58.61%\n",
      "Epoch: 1, Batch: 158, Loss: 0.6718, Accuracy: 58.70%, Precision: 58.60%\n",
      "Epoch: 1, Batch: 159, Loss: 0.5770, Accuracy: 58.71%, Precision: 58.62%\n",
      "Epoch: 1, Batch: 160, Loss: 0.5989, Accuracy: 58.72%, Precision: 58.63%\n",
      "Epoch: 1, Batch: 161, Loss: 0.5792, Accuracy: 58.74%, Precision: 58.66%\n",
      "Epoch: 1, Batch: 162, Loss: 0.6187, Accuracy: 58.74%, Precision: 58.66%\n",
      "Epoch: 1, Batch: 163, Loss: 0.7606, Accuracy: 58.72%, Precision: 58.63%\n",
      "Epoch: 1, Batch: 164, Loss: 0.6029, Accuracy: 58.74%, Precision: 58.65%\n",
      "Epoch: 1, Batch: 165, Loss: 0.6153, Accuracy: 58.75%, Precision: 58.66%\n",
      "Epoch: 1, Batch: 166, Loss: 0.6253, Accuracy: 58.77%, Precision: 58.67%\n",
      "Epoch: 1, Batch: 167, Loss: 0.6149, Accuracy: 58.78%, Precision: 58.69%\n",
      "Epoch: 1, Batch: 168, Loss: 0.5939, Accuracy: 58.80%, Precision: 58.70%\n",
      "Epoch: 1, Batch: 169, Loss: 0.6446, Accuracy: 58.81%, Precision: 58.69%\n",
      "Epoch: 1, Batch: 170, Loss: 0.6600, Accuracy: 58.82%, Precision: 58.69%\n",
      "Epoch: 1, Batch: 171, Loss: 0.6158, Accuracy: 58.81%, Precision: 58.69%\n",
      "Epoch: 1, Batch: 172, Loss: 0.6126, Accuracy: 58.81%, Precision: 58.68%\n",
      "Epoch: 1, Batch: 173, Loss: 0.5894, Accuracy: 58.83%, Precision: 58.70%\n",
      "Epoch: 1, Batch: 174, Loss: 0.6882, Accuracy: 58.84%, Precision: 58.71%\n",
      "Epoch: 1, Batch: 175, Loss: 0.6336, Accuracy: 58.83%, Precision: 58.71%\n",
      "Epoch: 1, Batch: 176, Loss: 0.5841, Accuracy: 58.86%, Precision: 58.72%\n",
      "Epoch: 1, Batch: 177, Loss: 0.5860, Accuracy: 58.87%, Precision: 58.74%\n",
      "Epoch: 1, Batch: 178, Loss: 0.5971, Accuracy: 58.88%, Precision: 58.76%\n",
      "Epoch: 1, Batch: 179, Loss: 0.6074, Accuracy: 58.90%, Precision: 58.79%\n",
      "Epoch: 1, Batch: 180, Loss: 0.6165, Accuracy: 58.92%, Precision: 58.82%\n",
      "Epoch: 1, Batch: 181, Loss: 0.5981, Accuracy: 58.93%, Precision: 58.84%\n",
      "Epoch: 1, Batch: 182, Loss: 0.5720, Accuracy: 58.95%, Precision: 58.87%\n",
      "Epoch: 1, Batch: 183, Loss: 0.7203, Accuracy: 58.96%, Precision: 58.87%\n",
      "Epoch: 1, Batch: 184, Loss: 0.5872, Accuracy: 58.97%, Precision: 58.87%\n",
      "Epoch: 1, Batch: 185, Loss: 0.6952, Accuracy: 58.98%, Precision: 58.89%\n",
      "Epoch: 1, Batch: 186, Loss: 0.6383, Accuracy: 58.96%, Precision: 58.86%\n",
      "Epoch: 1, Batch: 187, Loss: 0.7005, Accuracy: 58.95%, Precision: 58.85%\n",
      "Epoch: 1, Batch: 188, Loss: 0.5987, Accuracy: 58.98%, Precision: 58.88%\n",
      "Epoch: 1, Batch: 189, Loss: 0.4895, Accuracy: 58.99%, Precision: 58.90%\n",
      "Epoch: 1, Batch: 190, Loss: 0.4898, Accuracy: 59.02%, Precision: 58.93%\n",
      "Epoch: 1, Batch: 191, Loss: 0.6111, Accuracy: 59.03%, Precision: 58.94%\n",
      "Epoch: 1, Batch: 192, Loss: 0.7276, Accuracy: 59.03%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 193, Loss: 0.6553, Accuracy: 59.03%, Precision: 58.94%\n",
      "Epoch: 1, Batch: 194, Loss: 0.7070, Accuracy: 59.00%, Precision: 58.90%\n",
      "Epoch: 1, Batch: 195, Loss: 0.5963, Accuracy: 59.02%, Precision: 58.92%\n",
      "Epoch: 1, Batch: 196, Loss: 0.5929, Accuracy: 59.02%, Precision: 58.91%\n",
      "Epoch: 1, Batch: 197, Loss: 0.6997, Accuracy: 59.02%, Precision: 58.91%\n",
      "Epoch: 1, Batch: 198, Loss: 0.5594, Accuracy: 59.05%, Precision: 58.94%\n",
      "Epoch: 1, Batch: 199, Loss: 0.6411, Accuracy: 59.06%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 200, Loss: 0.6546, Accuracy: 59.06%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 201, Loss: 0.6120, Accuracy: 59.08%, Precision: 58.98%\n",
      "Epoch: 1, Batch: 202, Loss: 0.7326, Accuracy: 59.08%, Precision: 58.96%\n",
      "Epoch: 1, Batch: 203, Loss: 0.8038, Accuracy: 59.07%, Precision: 58.96%\n",
      "Epoch: 1, Batch: 204, Loss: 0.6375, Accuracy: 59.07%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 205, Loss: 0.5593, Accuracy: 59.08%, Precision: 58.96%\n",
      "Epoch: 1, Batch: 206, Loss: 0.6168, Accuracy: 59.09%, Precision: 58.98%\n",
      "Epoch: 1, Batch: 207, Loss: 0.6812, Accuracy: 59.07%, Precision: 58.96%\n",
      "Epoch: 1, Batch: 208, Loss: 0.6467, Accuracy: 59.08%, Precision: 58.98%\n",
      "Epoch: 1, Batch: 209, Loss: 0.6657, Accuracy: 59.09%, Precision: 58.98%\n",
      "Epoch: 1, Batch: 210, Loss: 0.6301, Accuracy: 59.09%, Precision: 58.98%\n",
      "Epoch: 1, Batch: 211, Loss: 0.6136, Accuracy: 59.07%, Precision: 58.96%\n",
      "Epoch: 1, Batch: 212, Loss: 0.6386, Accuracy: 59.06%, Precision: 58.97%\n",
      "Epoch: 1, Batch: 213, Loss: 0.6543, Accuracy: 59.07%, Precision: 58.96%\n",
      "Epoch: 1, Batch: 214, Loss: 0.5875, Accuracy: 59.07%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 215, Loss: 0.6648, Accuracy: 59.07%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 216, Loss: 0.6141, Accuracy: 59.07%, Precision: 58.94%\n",
      "Epoch: 1, Batch: 217, Loss: 0.5998, Accuracy: 59.07%, Precision: 58.93%\n",
      "Epoch: 1, Batch: 218, Loss: 0.6063, Accuracy: 59.07%, Precision: 58.93%\n",
      "Epoch: 1, Batch: 219, Loss: 0.5859, Accuracy: 59.09%, Precision: 58.96%\n",
      "Epoch: 1, Batch: 220, Loss: 0.6145, Accuracy: 59.09%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 221, Loss: 0.6746, Accuracy: 59.07%, Precision: 58.93%\n",
      "Epoch: 1, Batch: 222, Loss: 0.5673, Accuracy: 59.09%, Precision: 58.94%\n",
      "Epoch: 1, Batch: 223, Loss: 0.5924, Accuracy: 59.11%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 224, Loss: 0.6377, Accuracy: 59.11%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 225, Loss: 0.6249, Accuracy: 59.12%, Precision: 58.97%\n",
      "Epoch: 1, Batch: 226, Loss: 0.6668, Accuracy: 59.11%, Precision: 58.93%\n",
      "Epoch: 1, Batch: 227, Loss: 0.6408, Accuracy: 59.12%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 228, Loss: 0.5734, Accuracy: 59.13%, Precision: 58.95%\n",
      "Epoch: 1, Batch: 229, Loss: 0.5690, Accuracy: 59.15%, Precision: 58.98%\n",
      "Epoch: 1, Batch: 230, Loss: 0.5308, Accuracy: 59.17%, Precision: 59.01%\n",
      "Epoch: 1, Batch: 231, Loss: 0.6792, Accuracy: 59.16%, Precision: 59.01%\n",
      "Epoch: 1, Batch: 232, Loss: 0.6155, Accuracy: 59.17%, Precision: 59.02%\n",
      "Epoch: 1, Batch: 233, Loss: 0.7278, Accuracy: 59.17%, Precision: 59.01%\n",
      "Epoch: 1, Batch: 234, Loss: 0.6376, Accuracy: 59.17%, Precision: 59.02%\n",
      "Epoch: 1, Batch: 235, Loss: 0.7137, Accuracy: 59.17%, Precision: 59.02%\n",
      "Epoch: 1, Batch: 236, Loss: 0.6681, Accuracy: 59.17%, Precision: 59.01%\n",
      "Epoch: 1, Batch: 237, Loss: 0.6463, Accuracy: 59.17%, Precision: 59.01%\n",
      "Epoch: 1, Batch: 238, Loss: 0.5989, Accuracy: 59.18%, Precision: 59.02%\n",
      "Epoch: 1, Batch: 239, Loss: 0.6080, Accuracy: 59.20%, Precision: 59.04%\n",
      "Epoch: 1, Batch: 240, Loss: 0.4987, Accuracy: 59.23%, Precision: 59.07%\n",
      "Epoch: 1, Batch: 241, Loss: 0.5812, Accuracy: 59.24%, Precision: 59.08%\n",
      "Epoch: 1, Batch: 242, Loss: 0.6122, Accuracy: 59.25%, Precision: 59.08%\n",
      "Epoch: 1, Batch: 243, Loss: 0.7210, Accuracy: 59.26%, Precision: 59.09%\n",
      "Epoch: 1, Batch: 244, Loss: 0.5964, Accuracy: 59.27%, Precision: 59.09%\n",
      "Epoch: 1, Batch: 245, Loss: 0.6191, Accuracy: 59.27%, Precision: 59.10%\n",
      "Epoch: 1, Batch: 246, Loss: 0.6182, Accuracy: 59.28%, Precision: 59.10%\n",
      "Epoch: 1, Batch: 247, Loss: 0.6579, Accuracy: 59.27%, Precision: 59.07%\n",
      "Epoch: 1, Batch: 248, Loss: 0.5419, Accuracy: 59.28%, Precision: 59.09%\n",
      "Epoch: 1, Batch: 249, Loss: 0.7516, Accuracy: 59.28%, Precision: 59.09%\n",
      "Epoch: 1, Batch: 250, Loss: 0.5907, Accuracy: 59.29%, Precision: 59.12%\n",
      "Epoch: 1, Batch: 251, Loss: 0.6422, Accuracy: 59.30%, Precision: 59.13%\n",
      "Epoch: 1, Batch: 252, Loss: 0.5897, Accuracy: 59.31%, Precision: 59.13%\n",
      "Epoch: 1, Batch: 253, Loss: 0.6029, Accuracy: 59.32%, Precision: 59.12%\n",
      "Epoch: 1, Batch: 254, Loss: 0.5812, Accuracy: 59.33%, Precision: 59.12%\n",
      "Epoch: 1, Batch: 255, Loss: 0.6424, Accuracy: 59.33%, Precision: 59.11%\n",
      "Epoch: 1, Batch: 256, Loss: 0.6003, Accuracy: 59.34%, Precision: 59.12%\n",
      "Epoch: 1, Batch: 257, Loss: 0.5438, Accuracy: 59.35%, Precision: 59.13%\n",
      "Epoch: 1, Batch: 258, Loss: 0.7390, Accuracy: 59.36%, Precision: 59.14%\n",
      "Epoch: 1, Batch: 259, Loss: 0.5393, Accuracy: 59.37%, Precision: 59.15%\n",
      "Epoch: 1, Batch: 260, Loss: 0.5567, Accuracy: 59.37%, Precision: 59.15%\n",
      "Epoch: 1, Batch: 261, Loss: 0.6358, Accuracy: 59.38%, Precision: 59.16%\n",
      "Epoch: 1, Batch: 262, Loss: 0.4563, Accuracy: 59.41%, Precision: 59.18%\n",
      "Epoch: 1, Batch: 263, Loss: 0.6515, Accuracy: 59.41%, Precision: 59.17%\n",
      "Epoch: 1, Batch: 264, Loss: 0.5299, Accuracy: 59.43%, Precision: 59.20%\n",
      "Epoch: 1, Batch: 265, Loss: 0.5731, Accuracy: 59.45%, Precision: 59.22%\n",
      "Epoch: 1, Batch: 266, Loss: 0.5850, Accuracy: 59.46%, Precision: 59.22%\n",
      "Epoch: 1, Batch: 267, Loss: 0.5814, Accuracy: 59.47%, Precision: 59.23%\n",
      "Epoch: 1, Batch: 268, Loss: 0.5540, Accuracy: 59.47%, Precision: 59.22%\n",
      "Epoch: 1, Batch: 269, Loss: 0.5877, Accuracy: 59.48%, Precision: 59.23%\n",
      "Epoch: 1, Batch: 270, Loss: 0.5792, Accuracy: 59.48%, Precision: 59.23%\n",
      "Epoch: 1, Batch: 271, Loss: 0.5162, Accuracy: 59.50%, Precision: 59.25%\n",
      "Epoch: 1, Batch: 272, Loss: 0.6585, Accuracy: 59.51%, Precision: 59.27%\n",
      "Epoch: 1, Batch: 273, Loss: 0.6621, Accuracy: 59.52%, Precision: 59.27%\n",
      "Epoch: 1, Batch: 274, Loss: 0.5622, Accuracy: 59.53%, Precision: 59.29%\n",
      "Epoch: 1, Batch: 275, Loss: 0.5751, Accuracy: 59.54%, Precision: 59.28%\n",
      "Epoch: 1, Batch: 276, Loss: 0.5577, Accuracy: 59.55%, Precision: 59.30%\n",
      "Epoch: 1, Batch: 277, Loss: 0.4215, Accuracy: 59.57%, Precision: 59.34%\n",
      "Epoch: 1, Batch: 278, Loss: 0.5536, Accuracy: 59.58%, Precision: 59.35%\n",
      "Epoch: 1, Batch: 279, Loss: 0.6158, Accuracy: 59.59%, Precision: 59.35%\n",
      "Epoch: 1, Batch: 280, Loss: 0.6086, Accuracy: 59.60%, Precision: 59.37%\n",
      "Epoch: 1, Batch: 281, Loss: 0.6971, Accuracy: 59.61%, Precision: 59.38%\n",
      "Epoch: 1, Batch: 282, Loss: 0.8759, Accuracy: 59.60%, Precision: 59.36%\n",
      "Epoch: 1, Batch: 283, Loss: 0.6335, Accuracy: 59.61%, Precision: 59.36%\n",
      "Epoch: 1, Batch: 284, Loss: 0.8068, Accuracy: 59.59%, Precision: 59.34%\n",
      "Epoch: 1, Batch: 285, Loss: 0.6091, Accuracy: 59.60%, Precision: 59.35%\n",
      "Epoch: 1, Batch: 286, Loss: 0.6202, Accuracy: 59.61%, Precision: 59.36%\n",
      "Epoch: 1, Batch: 287, Loss: 0.6819, Accuracy: 59.60%, Precision: 59.38%\n",
      "Epoch: 1, Batch: 288, Loss: 0.5509, Accuracy: 59.61%, Precision: 59.38%\n",
      "Epoch: 1, Batch: 289, Loss: 0.5740, Accuracy: 59.61%, Precision: 59.38%\n",
      "Epoch: 1, Batch: 290, Loss: 0.5386, Accuracy: 59.62%, Precision: 59.38%\n",
      "Epoch: 1, Batch: 291, Loss: 0.6201, Accuracy: 59.62%, Precision: 59.39%\n",
      "Epoch: 1, Batch: 292, Loss: 0.5932, Accuracy: 59.62%, Precision: 59.40%\n",
      "Epoch: 1, Batch: 293, Loss: 0.5888, Accuracy: 59.63%, Precision: 59.39%\n",
      "Epoch: 1, Batch: 294, Loss: 0.6176, Accuracy: 59.64%, Precision: 59.40%\n",
      "Epoch: 1, Batch: 295, Loss: 0.5989, Accuracy: 59.65%, Precision: 59.41%\n",
      "Epoch: 1, Batch: 296, Loss: 0.7482, Accuracy: 59.65%, Precision: 59.42%\n",
      "Epoch: 1, Batch: 297, Loss: 0.6622, Accuracy: 59.66%, Precision: 59.43%\n",
      "Epoch: 1, Batch: 298, Loss: 0.5882, Accuracy: 59.67%, Precision: 59.44%\n",
      "Epoch: 1, Batch: 299, Loss: 0.6460, Accuracy: 59.67%, Precision: 59.43%\n",
      "Epoch: 1, Batch: 300, Loss: 0.6966, Accuracy: 59.67%, Precision: 59.43%\n",
      "Epoch: 1, Batch: 301, Loss: 0.6139, Accuracy: 59.67%, Precision: 59.45%\n",
      "Epoch: 1, Batch: 302, Loss: 0.6549, Accuracy: 59.66%, Precision: 59.44%\n",
      "Epoch: 1, Batch: 303, Loss: 0.6048, Accuracy: 59.67%, Precision: 59.45%\n",
      "Epoch: 1, Batch: 304, Loss: 0.6832, Accuracy: 59.67%, Precision: 59.46%\n",
      "Epoch: 1, Batch: 305, Loss: 0.6949, Accuracy: 59.67%, Precision: 59.45%\n",
      "Epoch: 1, Batch: 306, Loss: 0.5938, Accuracy: 59.69%, Precision: 59.47%\n",
      "Epoch: 1, Batch: 307, Loss: 0.5928, Accuracy: 59.70%, Precision: 59.48%\n",
      "Epoch: 1, Batch: 308, Loss: 0.6017, Accuracy: 59.71%, Precision: 59.48%\n",
      "Epoch: 1, Batch: 309, Loss: 0.5682, Accuracy: 59.71%, Precision: 59.49%\n",
      "Epoch: 1, Batch: 310, Loss: 0.7689, Accuracy: 59.71%, Precision: 59.48%\n",
      "Epoch: 1, Batch: 311, Loss: 0.5876, Accuracy: 59.71%, Precision: 59.48%\n",
      "Epoch: 1, Batch: 312, Loss: 0.6963, Accuracy: 59.70%, Precision: 59.46%\n",
      "Epoch: 1, Batch: 313, Loss: 0.6932, Accuracy: 59.68%, Precision: 59.44%\n",
      "Epoch: 1, Batch: 314, Loss: 0.6092, Accuracy: 59.70%, Precision: 59.44%\n",
      "Epoch: 1, Batch: 315, Loss: 0.5950, Accuracy: 59.70%, Precision: 59.45%\n",
      "Epoch: 1, Batch: 316, Loss: 0.6454, Accuracy: 59.70%, Precision: 59.44%\n",
      "Epoch: 1, Batch: 317, Loss: 0.6706, Accuracy: 59.70%, Precision: 59.43%\n",
      "Epoch: 1, Batch: 318, Loss: 0.6403, Accuracy: 59.70%, Precision: 59.42%\n",
      "Epoch: 1, Batch: 319, Loss: 0.6422, Accuracy: 59.71%, Precision: 59.41%\n",
      "Epoch: 1, Batch: 320, Loss: 0.5694, Accuracy: 59.72%, Precision: 59.43%\n",
      "Epoch: 1, Batch: 321, Loss: 0.5944, Accuracy: 59.73%, Precision: 59.43%\n",
      "Epoch: 1, Batch: 322, Loss: 0.6289, Accuracy: 59.73%, Precision: 59.41%\n",
      "Epoch: 1, Batch: 323, Loss: 0.6050, Accuracy: 59.74%, Precision: 59.42%\n",
      "Epoch: 1, Batch: 324, Loss: 0.5905, Accuracy: 59.75%, Precision: 59.42%\n",
      "Epoch: 1, Batch: 325, Loss: 0.6327, Accuracy: 59.76%, Precision: 59.42%\n",
      "Epoch: 1, Batch: 326, Loss: 0.5733, Accuracy: 59.77%, Precision: 59.43%\n",
      "Epoch: 1, Batch: 327, Loss: 0.5891, Accuracy: 59.77%, Precision: 59.44%\n",
      "Epoch: 1, Batch: 328, Loss: 0.5890, Accuracy: 59.78%, Precision: 59.46%\n",
      "Epoch: 1, Batch: 329, Loss: 0.5486, Accuracy: 59.80%, Precision: 59.48%\n",
      "Epoch: 1, Batch: 330, Loss: 0.5907, Accuracy: 59.81%, Precision: 59.50%\n",
      "Epoch: 1, Batch: 331, Loss: 0.7034, Accuracy: 59.82%, Precision: 59.50%\n",
      "Epoch: 1, Batch: 332, Loss: 0.6117, Accuracy: 59.83%, Precision: 59.52%\n",
      "Epoch: 1, Batch: 333, Loss: 0.6689, Accuracy: 59.82%, Precision: 59.52%\n",
      "Epoch: 1, Batch: 334, Loss: 0.6206, Accuracy: 59.83%, Precision: 59.53%\n",
      "Epoch: 1, Batch: 335, Loss: 0.6438, Accuracy: 59.83%, Precision: 59.51%\n",
      "Epoch: 1, Batch: 336, Loss: 0.6012, Accuracy: 59.84%, Precision: 59.52%\n",
      "Epoch: 1, Batch: 337, Loss: 0.5962, Accuracy: 59.85%, Precision: 59.52%\n",
      "Epoch: 1, Batch: 338, Loss: 0.6568, Accuracy: 59.85%, Precision: 59.50%\n",
      "Epoch: 1, Batch: 339, Loss: 0.6721, Accuracy: 59.84%, Precision: 59.49%\n",
      "Epoch: 1, Batch: 340, Loss: 0.6866, Accuracy: 59.83%, Precision: 59.49%\n",
      "Epoch: 1, Batch: 341, Loss: 0.5974, Accuracy: 59.85%, Precision: 59.52%\n",
      "Epoch: 1, Batch: 342, Loss: 0.5408, Accuracy: 59.87%, Precision: 59.53%\n",
      "Epoch: 1, Batch: 343, Loss: 0.5575, Accuracy: 59.89%, Precision: 59.54%\n",
      "Epoch: 1, Batch: 344, Loss: 0.7265, Accuracy: 59.89%, Precision: 59.54%\n",
      "Epoch: 1, Batch: 345, Loss: 0.6216, Accuracy: 59.90%, Precision: 59.55%\n",
      "Epoch: 1, Batch: 346, Loss: 0.6619, Accuracy: 59.90%, Precision: 59.55%\n",
      "Epoch: 1, Batch: 347, Loss: 0.6700, Accuracy: 59.90%, Precision: 59.53%\n",
      "Epoch: 1, Batch: 348, Loss: 0.6115, Accuracy: 59.90%, Precision: 59.53%\n",
      "Epoch: 1, Batch: 349, Loss: 0.5824, Accuracy: 59.91%, Precision: 59.53%\n",
      "Epoch: 1, Batch: 350, Loss: 0.6088, Accuracy: 59.93%, Precision: 59.55%\n",
      "Epoch: 1, Batch: 351, Loss: 0.6045, Accuracy: 59.93%, Precision: 59.55%\n",
      "Epoch: 1, Batch: 352, Loss: 0.7215, Accuracy: 59.92%, Precision: 59.53%\n",
      "Epoch: 1, Batch: 353, Loss: 0.6634, Accuracy: 59.92%, Precision: 59.53%\n",
      "Epoch: 1, Batch: 354, Loss: 0.6218, Accuracy: 59.91%, Precision: 59.51%\n",
      "Epoch: 1, Batch: 355, Loss: 0.5414, Accuracy: 59.93%, Precision: 59.53%\n",
      "Epoch: 1, Batch: 356, Loss: 0.6666, Accuracy: 59.92%, Precision: 59.54%\n",
      "Epoch: 1, Batch: 357, Loss: 0.5768, Accuracy: 59.92%, Precision: 59.54%\n",
      "Epoch: 1, Batch: 358, Loss: 0.6319, Accuracy: 59.93%, Precision: 59.56%\n",
      "Epoch: 1, Batch: 359, Loss: 0.5810, Accuracy: 59.94%, Precision: 59.57%\n",
      "Epoch: 1, Batch: 360, Loss: 0.8057, Accuracy: 59.95%, Precision: 59.57%\n",
      "Epoch: 1, Batch: 361, Loss: 0.6080, Accuracy: 59.96%, Precision: 59.59%\n",
      "Epoch: 1, Batch: 362, Loss: 0.6713, Accuracy: 59.97%, Precision: 59.60%\n",
      "Epoch: 1, Batch: 363, Loss: 0.6131, Accuracy: 59.97%, Precision: 59.61%\n",
      "Epoch: 1, Batch: 364, Loss: 0.6095, Accuracy: 59.97%, Precision: 59.61%\n",
      "Epoch: 1, Batch: 365, Loss: 0.5771, Accuracy: 59.99%, Precision: 59.63%\n",
      "Epoch: 1, Batch: 366, Loss: 0.5988, Accuracy: 59.99%, Precision: 59.63%\n",
      "Epoch: 1, Batch: 367, Loss: 0.6310, Accuracy: 60.01%, Precision: 59.63%\n",
      "Epoch: 1, Batch: 368, Loss: 0.6985, Accuracy: 60.01%, Precision: 59.61%\n",
      "Epoch: 1, Batch: 369, Loss: 0.5904, Accuracy: 60.02%, Precision: 59.62%\n",
      "Epoch: 1, Batch: 370, Loss: 0.5929, Accuracy: 60.02%, Precision: 59.63%\n",
      "Epoch: 1, Batch: 371, Loss: 0.5430, Accuracy: 60.04%, Precision: 59.64%\n",
      "Epoch: 1, Batch: 372, Loss: 0.6466, Accuracy: 60.05%, Precision: 59.63%\n",
      "Epoch: 1, Batch: 373, Loss: 0.6092, Accuracy: 60.05%, Precision: 59.63%\n",
      "Epoch: 1, Batch: 374, Loss: 0.7792, Accuracy: 60.04%, Precision: 59.62%\n",
      "Epoch: 1, Batch: 375, Loss: 0.6213, Accuracy: 60.06%, Precision: 59.63%\n",
      "Epoch: 1, Batch: 376, Loss: 0.8118, Accuracy: 60.05%, Precision: 59.63%\n",
      "Epoch: 1, Batch: 377, Loss: 0.5643, Accuracy: 60.06%, Precision: 59.65%\n",
      "Epoch: 1, Batch: 378, Loss: 0.5967, Accuracy: 60.06%, Precision: 59.65%\n",
      "Epoch: 1, Batch: 379, Loss: 0.6086, Accuracy: 60.07%, Precision: 59.66%\n",
      "Epoch: 1, Batch: 380, Loss: 0.6035, Accuracy: 60.08%, Precision: 59.67%\n",
      "Epoch: 1, Batch: 381, Loss: 0.5821, Accuracy: 60.10%, Precision: 59.68%\n",
      "Epoch: 1, Batch: 382, Loss: 0.5958, Accuracy: 60.10%, Precision: 59.68%\n",
      "Epoch: 1, Batch: 383, Loss: 0.5421, Accuracy: 60.11%, Precision: 59.70%\n",
      "Epoch: 1, Batch: 384, Loss: 0.6161, Accuracy: 60.12%, Precision: 59.71%\n",
      "Epoch: 1, Batch: 385, Loss: 0.5255, Accuracy: 60.13%, Precision: 59.72%\n",
      "Epoch: 1, Batch: 386, Loss: 0.6113, Accuracy: 60.13%, Precision: 59.72%\n",
      "Epoch: 1, Batch: 387, Loss: 0.5175, Accuracy: 60.15%, Precision: 59.73%\n",
      "Epoch: 1, Batch: 388, Loss: 0.6213, Accuracy: 60.16%, Precision: 59.73%\n",
      "Epoch: 1, Batch: 389, Loss: 0.6304, Accuracy: 60.17%, Precision: 59.74%\n",
      "Epoch: 1, Batch: 390, Loss: 0.5689, Accuracy: 60.17%, Precision: 59.75%\n",
      "Epoch: 1, Batch: 391, Loss: 0.6026, Accuracy: 60.19%, Precision: 59.76%\n",
      "Epoch: 1, Batch: 392, Loss: 0.6317, Accuracy: 60.19%, Precision: 59.76%\n",
      "Epoch: 1, Batch: 393, Loss: 0.5149, Accuracy: 60.20%, Precision: 59.77%\n",
      "Epoch: 1, Batch: 394, Loss: 0.5181, Accuracy: 60.22%, Precision: 59.78%\n",
      "Epoch: 1, Batch: 395, Loss: 0.5743, Accuracy: 60.23%, Precision: 59.78%\n",
      "Epoch: 1, Batch: 396, Loss: 0.5571, Accuracy: 60.24%, Precision: 59.79%\n",
      "Epoch: 1, Batch: 397, Loss: 0.7922, Accuracy: 60.22%, Precision: 59.76%\n",
      "Epoch: 1, Batch: 398, Loss: 0.4756, Accuracy: 60.25%, Precision: 59.79%\n",
      "Epoch: 1, Batch: 399, Loss: 0.7154, Accuracy: 60.25%, Precision: 59.79%\n",
      "Epoch: 1, Batch: 400, Loss: 0.6378, Accuracy: 60.25%, Precision: 59.79%\n",
      "Epoch: 1, Batch: 401, Loss: 0.5450, Accuracy: 60.26%, Precision: 59.80%\n",
      "Epoch: 1, Batch: 402, Loss: 0.5121, Accuracy: 60.26%, Precision: 59.81%\n",
      "Epoch: 1, Batch: 403, Loss: 0.5266, Accuracy: 60.27%, Precision: 59.82%\n",
      "Epoch: 1, Batch: 404, Loss: 0.6350, Accuracy: 60.27%, Precision: 59.79%\n",
      "Epoch: 1, Batch: 405, Loss: 0.6601, Accuracy: 60.27%, Precision: 59.80%\n",
      "Epoch: 1, Batch: 406, Loss: 0.5642, Accuracy: 60.28%, Precision: 59.81%\n",
      "Epoch: 1, Batch: 407, Loss: 0.6142, Accuracy: 60.29%, Precision: 59.82%\n",
      "Epoch: 1, Batch: 408, Loss: 0.5195, Accuracy: 60.31%, Precision: 59.84%\n",
      "Epoch: 1, Batch: 409, Loss: 0.6996, Accuracy: 60.30%, Precision: 59.81%\n",
      "Epoch: 1, Batch: 410, Loss: 0.6158, Accuracy: 60.30%, Precision: 59.81%\n",
      "Epoch: 1, Batch: 411, Loss: 0.5963, Accuracy: 60.30%, Precision: 59.81%\n",
      "Epoch: 1, Batch: 412, Loss: 0.6026, Accuracy: 60.30%, Precision: 59.82%\n",
      "Epoch: 1, Batch: 413, Loss: 0.6088, Accuracy: 60.31%, Precision: 59.83%\n",
      "Epoch: 1, Batch: 414, Loss: 0.5775, Accuracy: 60.31%, Precision: 59.83%\n",
      "Epoch: 1, Batch: 415, Loss: 0.5866, Accuracy: 60.31%, Precision: 59.83%\n",
      "Epoch: 1, Batch: 416, Loss: 0.5557, Accuracy: 60.32%, Precision: 59.84%\n",
      "Epoch: 1, Batch: 417, Loss: 0.5183, Accuracy: 60.33%, Precision: 59.85%\n",
      "Epoch: 1, Batch: 418, Loss: 0.5822, Accuracy: 60.34%, Precision: 59.85%\n",
      "Epoch: 1, Batch: 419, Loss: 0.6172, Accuracy: 60.35%, Precision: 59.85%\n",
      "Epoch: 1, Batch: 420, Loss: 0.5608, Accuracy: 60.35%, Precision: 59.86%\n",
      "Epoch: 1, Batch: 421, Loss: 0.6131, Accuracy: 60.36%, Precision: 59.87%\n",
      "Epoch: 1, Batch: 422, Loss: 0.5358, Accuracy: 60.37%, Precision: 59.88%\n",
      "Epoch: 1, Batch: 423, Loss: 0.7435, Accuracy: 60.37%, Precision: 59.89%\n",
      "Epoch: 1, Batch: 424, Loss: 0.6399, Accuracy: 60.38%, Precision: 59.89%\n",
      "Epoch: 1, Batch: 425, Loss: 0.6052, Accuracy: 60.38%, Precision: 59.89%\n",
      "Epoch: 1, Batch: 426, Loss: 0.5582, Accuracy: 60.39%, Precision: 59.90%\n",
      "Epoch: 1, Batch: 427, Loss: 0.6146, Accuracy: 60.39%, Precision: 59.90%\n",
      "Epoch: 1, Batch: 428, Loss: 0.6221, Accuracy: 60.40%, Precision: 59.92%\n",
      "Epoch: 1, Batch: 429, Loss: 0.6443, Accuracy: 60.40%, Precision: 59.91%\n",
      "Epoch: 1, Batch: 430, Loss: 0.5155, Accuracy: 60.41%, Precision: 59.92%\n",
      "Epoch: 1, Batch: 431, Loss: 0.6397, Accuracy: 60.42%, Precision: 59.91%\n",
      "Epoch: 1, Batch: 432, Loss: 0.5754, Accuracy: 60.43%, Precision: 59.92%\n",
      "Epoch: 1, Batch: 433, Loss: 0.5581, Accuracy: 60.44%, Precision: 59.94%\n",
      "Epoch: 1, Batch: 434, Loss: 0.5816, Accuracy: 60.45%, Precision: 59.95%\n",
      "Epoch: 1, Batch: 435, Loss: 0.6509, Accuracy: 60.45%, Precision: 59.94%\n",
      "Epoch: 1, Batch: 436, Loss: 0.6419, Accuracy: 60.46%, Precision: 59.94%\n",
      "Epoch: 1, Batch: 437, Loss: 0.5379, Accuracy: 60.47%, Precision: 59.95%\n",
      "Epoch: 1, Batch: 438, Loss: 0.6380, Accuracy: 60.48%, Precision: 59.95%\n",
      "Epoch: 1, Batch: 439, Loss: 0.5650, Accuracy: 60.48%, Precision: 59.95%\n",
      "Epoch: 1, Batch: 440, Loss: 0.5913, Accuracy: 60.50%, Precision: 59.95%\n",
      "Epoch: 1, Batch: 441, Loss: 0.5259, Accuracy: 60.51%, Precision: 59.95%\n",
      "Epoch: 1, Batch: 442, Loss: 0.5883, Accuracy: 60.51%, Precision: 59.96%\n",
      "Epoch: 1, Batch: 443, Loss: 0.7160, Accuracy: 60.51%, Precision: 59.97%\n",
      "Epoch: 1, Batch: 444, Loss: 0.5961, Accuracy: 60.52%, Precision: 59.98%\n",
      "Epoch: 1, Batch: 445, Loss: 0.5672, Accuracy: 60.53%, Precision: 60.00%\n",
      "Epoch: 1, Batch: 446, Loss: 0.5418, Accuracy: 60.55%, Precision: 60.00%\n",
      "Epoch: 1, Batch: 447, Loss: 0.5618, Accuracy: 60.55%, Precision: 60.02%\n",
      "Epoch: 1, Batch: 448, Loss: 0.6098, Accuracy: 60.56%, Precision: 60.02%\n",
      "Epoch: 1, Batch: 449, Loss: 0.6117, Accuracy: 60.56%, Precision: 60.02%\n",
      "Epoch: 1, Batch: 450, Loss: 0.5815, Accuracy: 60.56%, Precision: 60.03%\n",
      "Epoch: 1, Batch: 451, Loss: 0.6598, Accuracy: 60.56%, Precision: 60.03%\n",
      "Epoch: 1, Batch: 452, Loss: 0.7434, Accuracy: 60.56%, Precision: 60.02%\n",
      "Epoch: 1, Batch: 453, Loss: 0.7165, Accuracy: 60.55%, Precision: 60.03%\n",
      "Epoch: 1, Batch: 454, Loss: 0.5373, Accuracy: 60.56%, Precision: 60.02%\n",
      "Epoch: 1, Batch: 455, Loss: 0.6038, Accuracy: 60.57%, Precision: 60.03%\n",
      "Epoch: 1, Batch: 456, Loss: 0.5262, Accuracy: 60.59%, Precision: 60.04%\n",
      "Epoch: 1, Batch: 457, Loss: 0.7132, Accuracy: 60.59%, Precision: 60.04%\n",
      "Epoch: 1, Batch: 458, Loss: 0.5215, Accuracy: 60.60%, Precision: 60.05%\n",
      "Epoch: 1, Batch: 459, Loss: 0.6788, Accuracy: 60.60%, Precision: 60.04%\n",
      "Epoch: 1, Batch: 460, Loss: 0.6585, Accuracy: 60.60%, Precision: 60.04%\n",
      "Epoch: 1, Batch: 461, Loss: 0.6476, Accuracy: 60.61%, Precision: 60.05%\n",
      "Epoch: 1, Batch: 462, Loss: 0.5606, Accuracy: 60.62%, Precision: 60.06%\n",
      "Epoch: 1, Batch: 463, Loss: 0.5994, Accuracy: 60.62%, Precision: 60.06%\n",
      "Epoch: 1, Batch: 464, Loss: 0.5923, Accuracy: 60.62%, Precision: 60.07%\n",
      "Epoch: 1, Batch: 465, Loss: 0.5955, Accuracy: 60.63%, Precision: 60.08%\n",
      "Epoch: 1, Batch: 466, Loss: 0.5874, Accuracy: 60.65%, Precision: 60.10%\n",
      "Epoch: 1, Batch: 467, Loss: 0.5440, Accuracy: 60.65%, Precision: 60.11%\n",
      "Epoch: 1, Batch: 468, Loss: 0.6280, Accuracy: 60.67%, Precision: 60.12%\n",
      "Epoch: 1, Batch: 469, Loss: 0.5184, Accuracy: 60.69%, Precision: 60.15%\n",
      "Epoch: 1, Batch: 470, Loss: 0.6697, Accuracy: 60.69%, Precision: 60.15%\n",
      "Epoch: 1, Batch: 471, Loss: 0.5674, Accuracy: 60.70%, Precision: 60.16%\n",
      "Epoch: 1, Batch: 472, Loss: 0.5430, Accuracy: 60.71%, Precision: 60.17%\n",
      "Epoch: 1, Batch: 473, Loss: 0.6000, Accuracy: 60.72%, Precision: 60.18%\n",
      "Epoch: 1, Batch: 474, Loss: 0.5620, Accuracy: 60.72%, Precision: 60.17%\n",
      "Epoch: 1, Batch: 475, Loss: 0.5767, Accuracy: 60.73%, Precision: 60.17%\n",
      "Epoch: 1, Batch: 476, Loss: 0.5615, Accuracy: 60.74%, Precision: 60.19%\n",
      "Epoch: 1, Batch: 477, Loss: 0.6049, Accuracy: 60.74%, Precision: 60.20%\n",
      "Epoch: 1, Batch: 478, Loss: 0.6163, Accuracy: 60.74%, Precision: 60.19%\n",
      "Epoch: 1, Batch: 479, Loss: 0.7972, Accuracy: 60.74%, Precision: 60.19%\n",
      "Epoch: 1, Batch: 480, Loss: 0.5950, Accuracy: 60.75%, Precision: 60.19%\n",
      "Epoch: 1, Batch: 481, Loss: 0.7314, Accuracy: 60.74%, Precision: 60.19%\n",
      "Epoch: 1, Batch: 482, Loss: 0.4787, Accuracy: 60.76%, Precision: 60.20%\n",
      "Epoch: 1, Batch: 483, Loss: 0.5674, Accuracy: 60.77%, Precision: 60.21%\n",
      "Epoch: 1, Batch: 484, Loss: 0.6329, Accuracy: 60.77%, Precision: 60.21%\n",
      "Epoch: 1, Batch: 485, Loss: 0.5156, Accuracy: 60.79%, Precision: 60.21%\n",
      "Epoch: 1, Batch: 486, Loss: 0.5690, Accuracy: 60.80%, Precision: 60.23%\n",
      "Epoch: 1, Batch: 487, Loss: 0.5542, Accuracy: 60.82%, Precision: 60.24%\n",
      "Epoch: 1, Batch: 488, Loss: 0.5848, Accuracy: 60.82%, Precision: 60.24%\n",
      "Epoch: 1, Batch: 489, Loss: 0.5138, Accuracy: 60.83%, Precision: 60.26%\n",
      "Epoch: 1, Batch: 490, Loss: 0.5986, Accuracy: 60.84%, Precision: 60.27%\n",
      "Epoch: 1, Batch: 491, Loss: 0.6469, Accuracy: 60.84%, Precision: 60.28%\n",
      "Epoch: 1, Batch: 492, Loss: 0.5403, Accuracy: 60.85%, Precision: 60.29%\n",
      "Epoch: 1, Batch: 493, Loss: 0.6639, Accuracy: 60.85%, Precision: 60.29%\n",
      "Epoch: 1, Batch: 494, Loss: 0.6330, Accuracy: 60.86%, Precision: 60.31%\n",
      "Epoch: 1, Batch: 495, Loss: 0.5870, Accuracy: 60.86%, Precision: 60.31%\n",
      "Epoch: 1, Batch: 496, Loss: 0.7260, Accuracy: 60.86%, Precision: 60.29%\n",
      "Epoch: 1, Batch: 497, Loss: 0.5899, Accuracy: 60.86%, Precision: 60.31%\n",
      "Epoch: 1, Batch: 498, Loss: 0.6049, Accuracy: 60.87%, Precision: 60.30%\n",
      "Epoch: 1, Batch: 499, Loss: 0.6440, Accuracy: 60.87%, Precision: 60.31%\n",
      "Epoch: 1, Batch: 500, Loss: 0.4677, Accuracy: 60.90%, Precision: 60.34%\n",
      "Epoch: 1, Batch: 501, Loss: 0.5988, Accuracy: 60.91%, Precision: 60.35%\n",
      "Epoch: 1, Batch: 502, Loss: 0.5278, Accuracy: 60.92%, Precision: 60.36%\n",
      "Epoch: 1, Batch: 503, Loss: 0.6135, Accuracy: 60.92%, Precision: 60.35%\n",
      "Epoch: 1, Batch: 504, Loss: 0.7101, Accuracy: 60.91%, Precision: 60.34%\n",
      "Epoch: 1, Batch: 505, Loss: 0.6986, Accuracy: 60.90%, Precision: 60.33%\n",
      "Epoch: 1, Batch: 506, Loss: 0.5460, Accuracy: 60.91%, Precision: 60.34%\n",
      "Epoch: 1, Batch: 507, Loss: 0.6210, Accuracy: 60.92%, Precision: 60.33%\n",
      "Epoch: 1, Batch: 508, Loss: 0.5693, Accuracy: 60.93%, Precision: 60.34%\n",
      "Epoch: 1, Batch: 509, Loss: 0.5772, Accuracy: 60.93%, Precision: 60.35%\n",
      "Epoch: 1, Batch: 510, Loss: 0.6409, Accuracy: 60.94%, Precision: 60.35%\n",
      "Epoch: 1, Batch: 511, Loss: 0.6719, Accuracy: 60.93%, Precision: 60.35%\n",
      "Epoch: 1, Batch: 512, Loss: 0.5776, Accuracy: 60.94%, Precision: 60.35%\n",
      "Epoch: 1, Batch: 513, Loss: 0.5877, Accuracy: 60.94%, Precision: 60.36%\n",
      "Epoch: 1, Batch: 514, Loss: 0.5817, Accuracy: 60.95%, Precision: 60.36%\n",
      "Epoch: 1, Batch: 515, Loss: 0.5119, Accuracy: 60.96%, Precision: 60.37%\n",
      "Epoch: 1, Batch: 516, Loss: 0.7058, Accuracy: 60.95%, Precision: 60.36%\n",
      "Epoch: 1, Batch: 517, Loss: 0.5848, Accuracy: 60.96%, Precision: 60.36%\n",
      "Epoch: 1, Batch: 518, Loss: 0.5382, Accuracy: 60.96%, Precision: 60.36%\n",
      "Epoch: 1, Batch: 519, Loss: 0.5820, Accuracy: 60.96%, Precision: 60.36%\n",
      "Epoch: 1, Batch: 520, Loss: 0.5847, Accuracy: 60.97%, Precision: 60.37%\n",
      "Epoch: 1, Batch: 521, Loss: 0.5553, Accuracy: 60.98%, Precision: 60.39%\n",
      "Epoch: 1, Batch: 522, Loss: 0.5370, Accuracy: 60.99%, Precision: 60.39%\n",
      "Epoch: 1, Batch: 523, Loss: 0.5883, Accuracy: 61.00%, Precision: 60.40%\n",
      "Epoch: 1, Batch: 524, Loss: 0.5790, Accuracy: 61.01%, Precision: 60.41%\n",
      "Epoch: 1, Batch: 525, Loss: 0.5419, Accuracy: 61.03%, Precision: 60.42%\n",
      "Epoch: 1, Batch: 526, Loss: 0.5663, Accuracy: 61.03%, Precision: 60.43%\n",
      "Epoch: 1, Batch: 527, Loss: 0.5587, Accuracy: 61.04%, Precision: 60.43%\n",
      "Epoch: 1, Batch: 528, Loss: 0.6710, Accuracy: 61.03%, Precision: 60.44%\n",
      "Epoch: 1, Batch: 529, Loss: 0.5674, Accuracy: 61.03%, Precision: 60.43%\n",
      "Epoch: 1, Batch: 530, Loss: 0.5577, Accuracy: 61.04%, Precision: 60.42%\n",
      "Epoch: 1, Batch: 531, Loss: 0.5368, Accuracy: 61.05%, Precision: 60.42%\n",
      "Epoch: 1, Batch: 532, Loss: 0.8045, Accuracy: 61.05%, Precision: 60.42%\n",
      "Epoch: 1, Batch: 533, Loss: 0.5958, Accuracy: 61.06%, Precision: 60.44%\n",
      "Epoch: 1, Batch: 534, Loss: 0.6132, Accuracy: 61.06%, Precision: 60.42%\n",
      "Epoch: 1, Batch: 535, Loss: 0.6368, Accuracy: 61.06%, Precision: 60.42%\n",
      "Epoch: 1, Batch: 536, Loss: 0.6250, Accuracy: 61.07%, Precision: 60.42%\n",
      "Epoch: 1, Batch: 537, Loss: 0.5977, Accuracy: 61.07%, Precision: 60.42%\n",
      "Epoch: 1, Batch: 538, Loss: 0.5621, Accuracy: 61.07%, Precision: 60.43%\n",
      "Epoch: 1, Batch: 539, Loss: 0.5907, Accuracy: 61.08%, Precision: 60.43%\n",
      "Epoch: 1, Batch: 540, Loss: 0.6078, Accuracy: 61.08%, Precision: 60.44%\n",
      "Epoch: 1, Batch: 541, Loss: 0.5888, Accuracy: 61.09%, Precision: 60.45%\n",
      "Epoch: 1, Batch: 542, Loss: 0.5862, Accuracy: 61.09%, Precision: 60.45%\n",
      "Epoch: 1, Batch: 543, Loss: 0.6038, Accuracy: 61.10%, Precision: 60.46%\n",
      "Epoch: 1, Batch: 544, Loss: 0.6407, Accuracy: 61.10%, Precision: 60.47%\n",
      "Epoch: 1, Batch: 545, Loss: 0.5965, Accuracy: 61.10%, Precision: 60.46%\n",
      "Epoch: 1, Batch: 546, Loss: 0.6324, Accuracy: 61.11%, Precision: 60.46%\n",
      "Epoch: 1, Batch: 547, Loss: 0.6266, Accuracy: 61.11%, Precision: 60.46%\n",
      "Epoch: 1, Batch: 548, Loss: 0.6439, Accuracy: 61.12%, Precision: 60.47%\n",
      "Epoch: 1, Batch: 549, Loss: 0.5387, Accuracy: 61.13%, Precision: 60.48%\n",
      "Epoch: 1, Batch: 550, Loss: 0.6060, Accuracy: 61.13%, Precision: 60.48%\n",
      "Epoch: 1, Batch: 551, Loss: 0.5545, Accuracy: 61.14%, Precision: 60.49%\n",
      "Epoch: 1, Batch: 552, Loss: 0.6547, Accuracy: 61.15%, Precision: 60.50%\n",
      "Epoch: 1, Batch: 553, Loss: 0.7284, Accuracy: 61.14%, Precision: 60.49%\n",
      "Epoch: 1, Batch: 554, Loss: 0.6230, Accuracy: 61.14%, Precision: 60.49%\n",
      "Epoch: 1, Batch: 555, Loss: 0.5720, Accuracy: 61.15%, Precision: 60.50%\n",
      "Epoch: 1, Batch: 556, Loss: 0.5984, Accuracy: 61.15%, Precision: 60.50%\n",
      "Epoch: 1, Batch: 557, Loss: 0.6373, Accuracy: 61.16%, Precision: 60.51%\n",
      "Epoch: 1, Batch: 558, Loss: 0.5505, Accuracy: 61.17%, Precision: 60.52%\n",
      "Epoch: 1, Batch: 559, Loss: 0.5655, Accuracy: 61.17%, Precision: 60.52%\n",
      "Epoch: 1, Batch: 560, Loss: 0.6678, Accuracy: 61.17%, Precision: 60.51%\n",
      "Epoch: 1, Batch: 561, Loss: 0.6163, Accuracy: 61.16%, Precision: 60.50%\n",
      "Epoch: 1, Batch: 562, Loss: 0.6041, Accuracy: 61.16%, Precision: 60.49%\n",
      "Epoch: 1, Batch: 563, Loss: 0.5832, Accuracy: 61.17%, Precision: 60.49%\n",
      "Epoch: 1, Batch: 564, Loss: 0.5925, Accuracy: 61.17%, Precision: 60.50%\n",
      "Epoch: 1, Batch: 565, Loss: 0.5456, Accuracy: 61.19%, Precision: 60.52%\n",
      "Epoch: 1, Batch: 566, Loss: 0.5772, Accuracy: 61.19%, Precision: 60.52%\n",
      "Epoch: 1, Batch: 567, Loss: 0.5961, Accuracy: 61.20%, Precision: 60.52%\n",
      "Epoch: 1, Batch: 568, Loss: 0.5620, Accuracy: 61.21%, Precision: 60.53%\n",
      "Epoch: 1, Batch: 569, Loss: 0.6501, Accuracy: 61.21%, Precision: 60.54%\n",
      "Epoch: 1, Batch: 570, Loss: 0.5867, Accuracy: 61.22%, Precision: 60.55%\n",
      "Epoch: 1, Batch: 571, Loss: 0.7009, Accuracy: 61.21%, Precision: 60.54%\n",
      "Epoch: 1, Batch: 572, Loss: 0.5930, Accuracy: 61.21%, Precision: 60.54%\n",
      "Epoch: 1, Batch: 573, Loss: 0.7843, Accuracy: 61.21%, Precision: 60.55%\n",
      "Epoch: 1, Batch: 574, Loss: 0.6267, Accuracy: 61.22%, Precision: 60.54%\n",
      "Epoch: 1, Batch: 575, Loss: 0.6022, Accuracy: 61.22%, Precision: 60.56%\n",
      "Epoch: 1, Batch: 576, Loss: 0.5073, Accuracy: 61.23%, Precision: 60.57%\n",
      "Epoch: 1, Batch: 577, Loss: 0.6900, Accuracy: 61.23%, Precision: 60.56%\n",
      "Epoch: 1, Batch: 578, Loss: 0.5736, Accuracy: 61.24%, Precision: 60.57%\n",
      "Epoch: 1, Batch: 579, Loss: 0.5693, Accuracy: 61.24%, Precision: 60.57%\n",
      "Epoch: 1, Batch: 580, Loss: 0.6682, Accuracy: 61.24%, Precision: 60.57%\n",
      "Epoch: 1, Batch: 581, Loss: 0.7475, Accuracy: 61.24%, Precision: 60.57%\n",
      "Epoch: 1, Batch: 582, Loss: 0.7184, Accuracy: 61.23%, Precision: 60.55%\n",
      "Epoch: 1, Batch: 583, Loss: 0.4970, Accuracy: 61.25%, Precision: 60.57%\n",
      "Epoch: 1, Batch: 584, Loss: 0.6317, Accuracy: 61.25%, Precision: 60.57%\n",
      "Epoch: 1, Batch: 585, Loss: 0.6013, Accuracy: 61.25%, Precision: 60.57%\n",
      "Epoch: 1, Batch: 586, Loss: 0.6294, Accuracy: 61.24%, Precision: 60.58%\n",
      "Epoch: 1, Batch: 587, Loss: 0.5616, Accuracy: 61.26%, Precision: 60.60%\n",
      "Epoch: 1, Batch: 588, Loss: 0.5878, Accuracy: 61.26%, Precision: 60.61%\n",
      "Epoch: 1, Batch: 589, Loss: 0.7444, Accuracy: 61.26%, Precision: 60.59%\n",
      "Epoch: 1, Batch: 590, Loss: 0.4963, Accuracy: 61.27%, Precision: 60.61%\n",
      "Epoch: 1, Batch: 591, Loss: 0.7106, Accuracy: 61.27%, Precision: 60.62%\n",
      "Epoch: 1, Batch: 592, Loss: 0.5919, Accuracy: 61.27%, Precision: 60.61%\n",
      "Epoch: 1, Batch: 593, Loss: 0.6616, Accuracy: 61.28%, Precision: 60.63%\n",
      "Epoch: 1, Batch: 594, Loss: 0.5477, Accuracy: 61.30%, Precision: 60.64%\n",
      "Epoch: 1, Batch: 595, Loss: 0.6506, Accuracy: 61.30%, Precision: 60.64%\n",
      "Epoch: 1, Batch: 596, Loss: 0.5019, Accuracy: 61.31%, Precision: 60.66%\n",
      "Epoch: 1, Batch: 597, Loss: 0.6103, Accuracy: 61.31%, Precision: 60.66%\n",
      "Epoch: 1, Batch: 598, Loss: 0.5893, Accuracy: 61.32%, Precision: 60.67%\n",
      "Epoch: 1, Batch: 599, Loss: 0.6978, Accuracy: 61.31%, Precision: 60.67%\n",
      "Epoch: 1, Batch: 600, Loss: 0.7268, Accuracy: 61.31%, Precision: 60.66%\n",
      "Epoch: 1, Batch: 601, Loss: 0.6652, Accuracy: 61.30%, Precision: 60.65%\n",
      "Epoch: 1, Batch: 602, Loss: 0.7202, Accuracy: 61.30%, Precision: 60.63%\n",
      "Epoch: 1, Batch: 603, Loss: 0.6700, Accuracy: 61.29%, Precision: 60.63%\n",
      "Epoch: 1, Batch: 604, Loss: 0.6209, Accuracy: 61.30%, Precision: 60.63%\n",
      "Epoch: 1, Batch: 605, Loss: 0.5600, Accuracy: 61.31%, Precision: 60.64%\n",
      "Epoch: 1, Batch: 606, Loss: 0.6074, Accuracy: 61.32%, Precision: 60.64%\n",
      "Epoch: 1, Batch: 607, Loss: 0.5445, Accuracy: 61.33%, Precision: 60.65%\n",
      "Epoch: 1, Batch: 608, Loss: 0.5834, Accuracy: 61.33%, Precision: 60.65%\n",
      "Epoch: 1, Batch: 609, Loss: 0.5146, Accuracy: 61.34%, Precision: 60.66%\n",
      "Epoch: 2, Batch: 1, Loss: 0.6256, Accuracy: 61.35%, Precision: 60.67%\n",
      "Epoch: 2, Batch: 2, Loss: 0.5790, Accuracy: 61.36%, Precision: 60.69%\n",
      "Epoch: 2, Batch: 3, Loss: 0.5722, Accuracy: 61.37%, Precision: 60.69%\n",
      "Epoch: 2, Batch: 4, Loss: 0.6013, Accuracy: 61.37%, Precision: 60.70%\n",
      "Epoch: 2, Batch: 5, Loss: 0.5793, Accuracy: 61.38%, Precision: 60.70%\n",
      "Epoch: 2, Batch: 6, Loss: 0.6699, Accuracy: 61.38%, Precision: 60.69%\n",
      "Epoch: 2, Batch: 7, Loss: 0.4881, Accuracy: 61.39%, Precision: 60.70%\n",
      "Epoch: 2, Batch: 8, Loss: 0.5577, Accuracy: 61.39%, Precision: 60.71%\n",
      "Epoch: 2, Batch: 9, Loss: 0.6171, Accuracy: 61.39%, Precision: 60.71%\n",
      "Epoch: 2, Batch: 10, Loss: 0.5399, Accuracy: 61.40%, Precision: 60.73%\n",
      "Epoch: 2, Batch: 11, Loss: 0.6263, Accuracy: 61.41%, Precision: 60.74%\n",
      "Epoch: 2, Batch: 12, Loss: 0.5298, Accuracy: 61.42%, Precision: 60.75%\n",
      "Epoch: 2, Batch: 13, Loss: 0.6668, Accuracy: 61.42%, Precision: 60.75%\n",
      "Epoch: 2, Batch: 14, Loss: 0.6538, Accuracy: 61.41%, Precision: 60.74%\n",
      "Epoch: 2, Batch: 15, Loss: 0.5467, Accuracy: 61.42%, Precision: 60.75%\n",
      "Epoch: 2, Batch: 16, Loss: 0.5788, Accuracy: 61.42%, Precision: 60.75%\n",
      "Epoch: 2, Batch: 17, Loss: 0.5840, Accuracy: 61.42%, Precision: 60.75%\n",
      "Epoch: 2, Batch: 18, Loss: 0.5622, Accuracy: 61.42%, Precision: 60.75%\n",
      "Epoch: 2, Batch: 19, Loss: 0.6147, Accuracy: 61.43%, Precision: 60.75%\n",
      "Epoch: 2, Batch: 20, Loss: 0.5106, Accuracy: 61.45%, Precision: 60.77%\n",
      "Epoch: 2, Batch: 21, Loss: 0.4786, Accuracy: 61.46%, Precision: 60.78%\n",
      "Epoch: 2, Batch: 22, Loss: 0.6134, Accuracy: 61.46%, Precision: 60.77%\n",
      "Epoch: 2, Batch: 23, Loss: 0.4726, Accuracy: 61.48%, Precision: 60.78%\n",
      "Epoch: 2, Batch: 24, Loss: 0.5403, Accuracy: 61.49%, Precision: 60.79%\n",
      "Epoch: 2, Batch: 25, Loss: 0.6327, Accuracy: 61.50%, Precision: 60.80%\n",
      "Epoch: 2, Batch: 26, Loss: 0.5480, Accuracy: 61.50%, Precision: 60.80%\n",
      "Epoch: 2, Batch: 27, Loss: 0.5605, Accuracy: 61.51%, Precision: 60.81%\n",
      "Epoch: 2, Batch: 28, Loss: 0.5715, Accuracy: 61.52%, Precision: 60.82%\n",
      "Epoch: 2, Batch: 29, Loss: 0.5374, Accuracy: 61.52%, Precision: 60.83%\n",
      "Epoch: 2, Batch: 30, Loss: 0.4567, Accuracy: 61.54%, Precision: 60.83%\n",
      "Epoch: 2, Batch: 31, Loss: 0.6499, Accuracy: 61.53%, Precision: 60.82%\n",
      "Epoch: 2, Batch: 32, Loss: 0.6101, Accuracy: 61.53%, Precision: 60.82%\n",
      "Epoch: 2, Batch: 33, Loss: 0.5608, Accuracy: 61.54%, Precision: 60.83%\n",
      "Epoch: 2, Batch: 34, Loss: 0.4733, Accuracy: 61.56%, Precision: 60.86%\n",
      "Epoch: 2, Batch: 35, Loss: 0.6528, Accuracy: 61.56%, Precision: 60.87%\n",
      "Epoch: 2, Batch: 36, Loss: 0.6119, Accuracy: 61.56%, Precision: 60.86%\n",
      "Epoch: 2, Batch: 37, Loss: 0.5250, Accuracy: 61.58%, Precision: 60.88%\n",
      "Epoch: 2, Batch: 38, Loss: 0.6185, Accuracy: 61.59%, Precision: 60.89%\n",
      "Epoch: 2, Batch: 39, Loss: 0.6118, Accuracy: 61.59%, Precision: 60.91%\n",
      "Epoch: 2, Batch: 40, Loss: 0.9017, Accuracy: 61.60%, Precision: 60.91%\n",
      "Epoch: 2, Batch: 41, Loss: 0.5967, Accuracy: 61.60%, Precision: 60.92%\n",
      "Epoch: 2, Batch: 42, Loss: 0.4342, Accuracy: 61.62%, Precision: 60.93%\n",
      "Epoch: 2, Batch: 43, Loss: 0.5724, Accuracy: 61.63%, Precision: 60.94%\n",
      "Epoch: 2, Batch: 44, Loss: 0.6441, Accuracy: 61.64%, Precision: 60.94%\n",
      "Epoch: 2, Batch: 45, Loss: 0.6186, Accuracy: 61.64%, Precision: 60.94%\n",
      "Epoch: 2, Batch: 46, Loss: 0.6288, Accuracy: 61.64%, Precision: 60.94%\n",
      "Epoch: 2, Batch: 47, Loss: 0.6823, Accuracy: 61.65%, Precision: 60.96%\n",
      "Epoch: 2, Batch: 48, Loss: 0.5894, Accuracy: 61.66%, Precision: 60.95%\n",
      "Epoch: 2, Batch: 49, Loss: 0.6461, Accuracy: 61.66%, Precision: 60.95%\n",
      "Epoch: 2, Batch: 50, Loss: 0.5576, Accuracy: 61.66%, Precision: 60.96%\n",
      "Epoch: 2, Batch: 51, Loss: 0.5714, Accuracy: 61.67%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 52, Loss: 0.6983, Accuracy: 61.66%, Precision: 60.97%\n",
      "Epoch: 2, Batch: 53, Loss: 0.5806, Accuracy: 61.67%, Precision: 60.97%\n",
      "Epoch: 2, Batch: 54, Loss: 0.6051, Accuracy: 61.67%, Precision: 60.97%\n",
      "Epoch: 2, Batch: 55, Loss: 0.6349, Accuracy: 61.67%, Precision: 60.95%\n",
      "Epoch: 2, Batch: 56, Loss: 0.5745, Accuracy: 61.67%, Precision: 60.95%\n",
      "Epoch: 2, Batch: 57, Loss: 0.7832, Accuracy: 61.66%, Precision: 60.96%\n",
      "Epoch: 2, Batch: 58, Loss: 0.5516, Accuracy: 61.66%, Precision: 60.96%\n",
      "Epoch: 2, Batch: 59, Loss: 0.6197, Accuracy: 61.67%, Precision: 60.97%\n",
      "Epoch: 2, Batch: 60, Loss: 0.5785, Accuracy: 61.67%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 61, Loss: 0.5420, Accuracy: 61.68%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 62, Loss: 0.6064, Accuracy: 61.67%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 63, Loss: 0.5756, Accuracy: 61.68%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 64, Loss: 0.6259, Accuracy: 61.68%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 65, Loss: 0.6023, Accuracy: 61.68%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 66, Loss: 0.5465, Accuracy: 61.69%, Precision: 61.00%\n",
      "Epoch: 2, Batch: 67, Loss: 0.5869, Accuracy: 61.69%, Precision: 61.00%\n",
      "Epoch: 2, Batch: 68, Loss: 0.5804, Accuracy: 61.70%, Precision: 61.01%\n",
      "Epoch: 2, Batch: 69, Loss: 0.5525, Accuracy: 61.70%, Precision: 61.01%\n",
      "Epoch: 2, Batch: 70, Loss: 0.5789, Accuracy: 61.71%, Precision: 61.01%\n",
      "Epoch: 2, Batch: 71, Loss: 0.5224, Accuracy: 61.72%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 72, Loss: 0.5865, Accuracy: 61.72%, Precision: 61.02%\n",
      "Epoch: 2, Batch: 73, Loss: 0.5731, Accuracy: 61.73%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 74, Loss: 0.6791, Accuracy: 61.73%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 75, Loss: 0.5935, Accuracy: 61.74%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 76, Loss: 0.5486, Accuracy: 61.74%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 77, Loss: 0.7027, Accuracy: 61.73%, Precision: 61.01%\n",
      "Epoch: 2, Batch: 78, Loss: 0.5267, Accuracy: 61.74%, Precision: 61.02%\n",
      "Epoch: 2, Batch: 79, Loss: 0.5698, Accuracy: 61.74%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 80, Loss: 0.5225, Accuracy: 61.75%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 81, Loss: 0.5673, Accuracy: 61.76%, Precision: 61.04%\n",
      "Epoch: 2, Batch: 82, Loss: 0.6260, Accuracy: 61.76%, Precision: 61.04%\n",
      "Epoch: 2, Batch: 83, Loss: 0.6017, Accuracy: 61.76%, Precision: 61.04%\n",
      "Epoch: 2, Batch: 84, Loss: 0.5120, Accuracy: 61.77%, Precision: 61.05%\n",
      "Epoch: 2, Batch: 85, Loss: 0.6044, Accuracy: 61.76%, Precision: 61.04%\n",
      "Epoch: 2, Batch: 86, Loss: 0.5754, Accuracy: 61.76%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 87, Loss: 0.7421, Accuracy: 61.77%, Precision: 61.04%\n",
      "Epoch: 2, Batch: 88, Loss: 0.6724, Accuracy: 61.77%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 89, Loss: 0.6579, Accuracy: 61.76%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 90, Loss: 0.7586, Accuracy: 61.76%, Precision: 61.01%\n",
      "Epoch: 2, Batch: 91, Loss: 0.6242, Accuracy: 61.75%, Precision: 61.00%\n",
      "Epoch: 2, Batch: 92, Loss: 0.6241, Accuracy: 61.75%, Precision: 61.00%\n",
      "Epoch: 2, Batch: 93, Loss: 0.6476, Accuracy: 61.75%, Precision: 61.00%\n",
      "Epoch: 2, Batch: 94, Loss: 0.6476, Accuracy: 61.75%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 95, Loss: 0.6334, Accuracy: 61.74%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 96, Loss: 0.7200, Accuracy: 61.74%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 97, Loss: 0.6575, Accuracy: 61.74%, Precision: 60.97%\n",
      "Epoch: 2, Batch: 98, Loss: 0.5996, Accuracy: 61.73%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 99, Loss: 0.7010, Accuracy: 61.73%, Precision: 60.97%\n",
      "Epoch: 2, Batch: 100, Loss: 0.5963, Accuracy: 61.73%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 101, Loss: 0.6393, Accuracy: 61.73%, Precision: 60.97%\n",
      "Epoch: 2, Batch: 102, Loss: 0.6098, Accuracy: 61.74%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 103, Loss: 0.6280, Accuracy: 61.74%, Precision: 60.97%\n",
      "Epoch: 2, Batch: 104, Loss: 0.6114, Accuracy: 61.75%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 105, Loss: 0.5943, Accuracy: 61.75%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 106, Loss: 0.6125, Accuracy: 61.75%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 107, Loss: 0.6408, Accuracy: 61.74%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 108, Loss: 0.5928, Accuracy: 61.74%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 109, Loss: 0.6091, Accuracy: 61.75%, Precision: 60.98%\n",
      "Epoch: 2, Batch: 110, Loss: 0.6034, Accuracy: 61.75%, Precision: 60.99%\n",
      "Epoch: 2, Batch: 111, Loss: 0.6073, Accuracy: 61.76%, Precision: 61.01%\n",
      "Epoch: 2, Batch: 112, Loss: 0.6224, Accuracy: 61.76%, Precision: 61.01%\n",
      "Epoch: 2, Batch: 113, Loss: 0.6677, Accuracy: 61.75%, Precision: 61.01%\n",
      "Epoch: 2, Batch: 114, Loss: 0.6062, Accuracy: 61.76%, Precision: 61.02%\n",
      "Epoch: 2, Batch: 115, Loss: 0.6688, Accuracy: 61.75%, Precision: 61.02%\n",
      "Epoch: 2, Batch: 116, Loss: 0.6617, Accuracy: 61.75%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 117, Loss: 0.6241, Accuracy: 61.75%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 118, Loss: 0.6013, Accuracy: 61.76%, Precision: 61.04%\n",
      "Epoch: 2, Batch: 119, Loss: 0.6200, Accuracy: 61.76%, Precision: 61.02%\n",
      "Epoch: 2, Batch: 120, Loss: 0.5365, Accuracy: 61.76%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 121, Loss: 0.7248, Accuracy: 61.76%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 122, Loss: 0.5783, Accuracy: 61.76%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 123, Loss: 0.5957, Accuracy: 61.77%, Precision: 61.03%\n",
      "Epoch: 2, Batch: 124, Loss: 0.7683, Accuracy: 61.78%, Precision: 61.04%\n",
      "Epoch: 2, Batch: 125, Loss: 0.5721, Accuracy: 61.79%, Precision: 61.04%\n",
      "Epoch: 2, Batch: 126, Loss: 0.6076, Accuracy: 61.80%, Precision: 61.06%\n",
      "Epoch: 2, Batch: 127, Loss: 0.6151, Accuracy: 61.80%, Precision: 61.05%\n",
      "Epoch: 2, Batch: 128, Loss: 0.6539, Accuracy: 61.81%, Precision: 61.05%\n",
      "Epoch: 2, Batch: 129, Loss: 0.6210, Accuracy: 61.81%, Precision: 61.05%\n",
      "Epoch: 2, Batch: 130, Loss: 0.6487, Accuracy: 61.81%, Precision: 61.05%\n",
      "Epoch: 2, Batch: 131, Loss: 0.6044, Accuracy: 61.82%, Precision: 61.07%\n",
      "Epoch: 2, Batch: 132, Loss: 0.5811, Accuracy: 61.83%, Precision: 61.07%\n",
      "Epoch: 2, Batch: 133, Loss: 0.5262, Accuracy: 61.83%, Precision: 61.08%\n",
      "Epoch: 2, Batch: 134, Loss: 0.5384, Accuracy: 61.84%, Precision: 61.09%\n",
      "Epoch: 2, Batch: 135, Loss: 0.4908, Accuracy: 61.85%, Precision: 61.10%\n",
      "Epoch: 2, Batch: 136, Loss: 0.6586, Accuracy: 61.85%, Precision: 61.09%\n",
      "Epoch: 2, Batch: 137, Loss: 0.6069, Accuracy: 61.86%, Precision: 61.10%\n",
      "Epoch: 2, Batch: 138, Loss: 0.5765, Accuracy: 61.87%, Precision: 61.10%\n",
      "Epoch: 2, Batch: 139, Loss: 0.4957, Accuracy: 61.88%, Precision: 61.11%\n",
      "Epoch: 2, Batch: 140, Loss: 0.6336, Accuracy: 61.88%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 141, Loss: 0.7172, Accuracy: 61.87%, Precision: 61.11%\n",
      "Epoch: 2, Batch: 142, Loss: 0.8430, Accuracy: 61.87%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 143, Loss: 0.5753, Accuracy: 61.88%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 144, Loss: 0.6369, Accuracy: 61.88%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 145, Loss: 0.5746, Accuracy: 61.88%, Precision: 61.11%\n",
      "Epoch: 2, Batch: 146, Loss: 0.7352, Accuracy: 61.87%, Precision: 61.10%\n",
      "Epoch: 2, Batch: 147, Loss: 0.5820, Accuracy: 61.87%, Precision: 61.10%\n",
      "Epoch: 2, Batch: 148, Loss: 0.6045, Accuracy: 61.87%, Precision: 61.09%\n",
      "Epoch: 2, Batch: 149, Loss: 0.5270, Accuracy: 61.88%, Precision: 61.10%\n",
      "Epoch: 2, Batch: 150, Loss: 0.6060, Accuracy: 61.89%, Precision: 61.10%\n",
      "Epoch: 2, Batch: 151, Loss: 0.5801, Accuracy: 61.89%, Precision: 61.11%\n",
      "Epoch: 2, Batch: 152, Loss: 0.6237, Accuracy: 61.90%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 153, Loss: 0.6076, Accuracy: 61.90%, Precision: 61.11%\n",
      "Epoch: 2, Batch: 154, Loss: 0.5425, Accuracy: 61.91%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 155, Loss: 0.5779, Accuracy: 61.92%, Precision: 61.13%\n",
      "Epoch: 2, Batch: 156, Loss: 0.6109, Accuracy: 61.92%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 157, Loss: 0.6043, Accuracy: 61.92%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 158, Loss: 0.5498, Accuracy: 61.93%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 159, Loss: 0.6262, Accuracy: 61.93%, Precision: 61.12%\n",
      "Epoch: 2, Batch: 160, Loss: 0.5817, Accuracy: 61.93%, Precision: 61.13%\n",
      "Epoch: 2, Batch: 161, Loss: 0.6017, Accuracy: 61.94%, Precision: 61.14%\n",
      "Epoch: 2, Batch: 162, Loss: 0.5231, Accuracy: 61.96%, Precision: 61.15%\n",
      "Epoch: 2, Batch: 163, Loss: 0.6734, Accuracy: 61.96%, Precision: 61.15%\n",
      "Epoch: 2, Batch: 164, Loss: 0.6144, Accuracy: 61.96%, Precision: 61.15%\n",
      "Epoch: 2, Batch: 165, Loss: 0.5960, Accuracy: 61.97%, Precision: 61.17%\n",
      "Epoch: 2, Batch: 166, Loss: 0.5720, Accuracy: 61.97%, Precision: 61.16%\n",
      "Epoch: 2, Batch: 167, Loss: 0.6261, Accuracy: 61.97%, Precision: 61.15%\n",
      "Epoch: 2, Batch: 168, Loss: 0.5218, Accuracy: 61.98%, Precision: 61.16%\n",
      "Epoch: 2, Batch: 169, Loss: 0.6603, Accuracy: 61.98%, Precision: 61.17%\n",
      "Epoch: 2, Batch: 170, Loss: 0.5351, Accuracy: 62.00%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 171, Loss: 0.5473, Accuracy: 62.00%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 172, Loss: 0.7213, Accuracy: 62.00%, Precision: 61.18%\n",
      "Epoch: 2, Batch: 173, Loss: 0.7360, Accuracy: 61.99%, Precision: 61.17%\n",
      "Epoch: 2, Batch: 174, Loss: 0.5236, Accuracy: 62.00%, Precision: 61.18%\n",
      "Epoch: 2, Batch: 175, Loss: 0.6737, Accuracy: 62.00%, Precision: 61.18%\n",
      "Epoch: 2, Batch: 176, Loss: 0.5566, Accuracy: 62.00%, Precision: 61.18%\n",
      "Epoch: 2, Batch: 177, Loss: 0.4993, Accuracy: 62.02%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 178, Loss: 0.6386, Accuracy: 62.01%, Precision: 61.18%\n",
      "Epoch: 2, Batch: 179, Loss: 0.7400, Accuracy: 62.01%, Precision: 61.17%\n",
      "Epoch: 2, Batch: 180, Loss: 0.7078, Accuracy: 62.01%, Precision: 61.16%\n",
      "Epoch: 2, Batch: 181, Loss: 0.5999, Accuracy: 62.01%, Precision: 61.17%\n",
      "Epoch: 2, Batch: 182, Loss: 0.5696, Accuracy: 62.02%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 183, Loss: 0.5211, Accuracy: 62.03%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 184, Loss: 0.6285, Accuracy: 62.03%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 185, Loss: 0.6126, Accuracy: 62.03%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 186, Loss: 0.6515, Accuracy: 62.03%, Precision: 61.20%\n",
      "Epoch: 2, Batch: 187, Loss: 0.6128, Accuracy: 62.03%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 188, Loss: 0.6028, Accuracy: 62.03%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 189, Loss: 0.6653, Accuracy: 62.03%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 190, Loss: 0.5615, Accuracy: 62.04%, Precision: 61.20%\n",
      "Epoch: 2, Batch: 191, Loss: 0.6099, Accuracy: 62.03%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 192, Loss: 0.6219, Accuracy: 62.04%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 193, Loss: 0.5788, Accuracy: 62.03%, Precision: 61.18%\n",
      "Epoch: 2, Batch: 194, Loss: 0.5626, Accuracy: 62.04%, Precision: 61.18%\n",
      "Epoch: 2, Batch: 195, Loss: 0.6091, Accuracy: 62.05%, Precision: 61.19%\n",
      "Epoch: 2, Batch: 196, Loss: 0.5187, Accuracy: 62.06%, Precision: 61.20%\n",
      "Epoch: 2, Batch: 197, Loss: 0.4686, Accuracy: 62.07%, Precision: 61.21%\n",
      "Epoch: 2, Batch: 198, Loss: 0.6779, Accuracy: 62.07%, Precision: 61.21%\n",
      "Epoch: 2, Batch: 199, Loss: 0.4845, Accuracy: 62.07%, Precision: 61.20%\n",
      "Epoch: 2, Batch: 200, Loss: 0.8371, Accuracy: 62.07%, Precision: 61.21%\n",
      "Epoch: 2, Batch: 201, Loss: 0.5601, Accuracy: 62.07%, Precision: 61.21%\n",
      "Epoch: 2, Batch: 202, Loss: 0.6446, Accuracy: 62.07%, Precision: 61.21%\n",
      "Epoch: 2, Batch: 203, Loss: 0.4923, Accuracy: 62.09%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 204, Loss: 0.5785, Accuracy: 62.08%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 205, Loss: 0.5561, Accuracy: 62.09%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 206, Loss: 0.7000, Accuracy: 62.09%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 207, Loss: 0.6323, Accuracy: 62.09%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 208, Loss: 0.7332, Accuracy: 62.09%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 209, Loss: 0.7544, Accuracy: 62.08%, Precision: 61.22%\n",
      "Epoch: 2, Batch: 210, Loss: 0.5914, Accuracy: 62.08%, Precision: 61.22%\n",
      "Epoch: 2, Batch: 211, Loss: 0.5677, Accuracy: 62.09%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 212, Loss: 0.5705, Accuracy: 62.08%, Precision: 61.22%\n",
      "Epoch: 2, Batch: 213, Loss: 0.5623, Accuracy: 62.09%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 214, Loss: 0.5809, Accuracy: 62.09%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 215, Loss: 0.6737, Accuracy: 62.09%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 216, Loss: 0.7401, Accuracy: 62.09%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 217, Loss: 0.6354, Accuracy: 62.09%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 218, Loss: 0.6083, Accuracy: 62.09%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 219, Loss: 0.6249, Accuracy: 62.10%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 220, Loss: 0.5994, Accuracy: 62.10%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 221, Loss: 0.6068, Accuracy: 62.11%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 222, Loss: 0.6030, Accuracy: 62.12%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 223, Loss: 0.5560, Accuracy: 62.12%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 224, Loss: 0.6523, Accuracy: 62.12%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 225, Loss: 0.5681, Accuracy: 62.13%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 226, Loss: 0.6065, Accuracy: 62.13%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 227, Loss: 0.5954, Accuracy: 62.13%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 228, Loss: 0.6087, Accuracy: 62.13%, Precision: 61.27%\n",
      "Epoch: 2, Batch: 229, Loss: 0.5875, Accuracy: 62.14%, Precision: 61.27%\n",
      "Epoch: 2, Batch: 230, Loss: 0.5344, Accuracy: 62.14%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 231, Loss: 0.6597, Accuracy: 62.14%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 232, Loss: 0.6459, Accuracy: 62.13%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 233, Loss: 0.5753, Accuracy: 62.14%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 234, Loss: 0.6606, Accuracy: 62.13%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 235, Loss: 0.5778, Accuracy: 62.14%, Precision: 61.23%\n",
      "Epoch: 2, Batch: 236, Loss: 0.5839, Accuracy: 62.14%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 237, Loss: 0.6422, Accuracy: 62.15%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 238, Loss: 0.6134, Accuracy: 62.15%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 239, Loss: 0.6309, Accuracy: 62.15%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 240, Loss: 0.6638, Accuracy: 62.15%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 241, Loss: 0.4933, Accuracy: 62.16%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 242, Loss: 0.5867, Accuracy: 62.16%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 243, Loss: 0.5887, Accuracy: 62.16%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 244, Loss: 0.5999, Accuracy: 62.15%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 245, Loss: 0.6106, Accuracy: 62.15%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 246, Loss: 0.6187, Accuracy: 62.15%, Precision: 61.24%\n",
      "Epoch: 2, Batch: 247, Loss: 0.5615, Accuracy: 62.16%, Precision: 61.25%\n",
      "Epoch: 2, Batch: 248, Loss: 0.5388, Accuracy: 62.16%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 249, Loss: 0.7540, Accuracy: 62.17%, Precision: 61.27%\n",
      "Epoch: 2, Batch: 250, Loss: 0.6799, Accuracy: 62.17%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 251, Loss: 0.6390, Accuracy: 62.17%, Precision: 61.26%\n",
      "Epoch: 2, Batch: 252, Loss: 0.5293, Accuracy: 62.18%, Precision: 61.28%\n",
      "Epoch: 2, Batch: 253, Loss: 0.5785, Accuracy: 62.18%, Precision: 61.28%\n",
      "Epoch: 2, Batch: 254, Loss: 0.5842, Accuracy: 62.19%, Precision: 61.29%\n",
      "Epoch: 2, Batch: 255, Loss: 0.5478, Accuracy: 62.19%, Precision: 61.30%\n",
      "Epoch: 2, Batch: 256, Loss: 0.6319, Accuracy: 62.19%, Precision: 61.30%\n",
      "Epoch: 2, Batch: 257, Loss: 0.5123, Accuracy: 62.19%, Precision: 61.31%\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "print(model)\n",
    "device = get_device()\n",
    "model.to(device)\n",
    "model.train()\n",
    "loss_hist = []\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "true_negatives = 0\n",
    "false_negatives = 0\n",
    "epochs = 20\n",
    "\n",
    "for e in range(epochs):\n",
    "    i = 1\n",
    "    loss_per_epoch = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        # Perform forward pass, compute loss, and update the model\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        labels = labels.long()\n",
    "        bs, c, time, feats = inputs.shape\n",
    "        inputs = inputs.reshape(bs, feats, time)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_per_epoch += loss.item()\n",
    "        # Calculate accuracy\n",
    "        # print('a',outputs.data)\n",
    "        # print('b',torch.max(outputs.data, 1))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate precision\n",
    "        true_positives += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "        false_positives += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "        true_negatives += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "        false_negatives += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print metrics\n",
    "        print(\"Epoch: {}, Batch: {}, Loss: {:.4f}, Accuracy: {:.2f}%, Precision: {:.2f}%\".format(\n",
    "            e, i, loss.item(), (correct_predictions / total_predictions) * 100,\n",
    "            (true_positives / (true_positives + false_positives + 1e-12)) * 100  # Add small epsilon to avoid division by zero\n",
    "        ))\n",
    "\n",
    "        i += 1\n",
    "    loss_hist.append(loss_per_epoch/i)\n",
    "    writer.add_scalar(\"Loss/gates\", loss_per_epoch/i, e)\n",
    "    writer.flush()\n",
    "# rename before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename !\n",
    "torch.save(model.state_dict(), \"./model/model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of epochs\n",
    "epochs = range(1, len(loss_hist) + 1)\n",
    "\n",
    "# Plot the training loss as a curve\n",
    "plt.plot(epochs, loss_hist, 'b-', label='Training loss')\n",
    "\n",
    "# Add a title and axis labels\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path warning!! Colab dir are different\n",
    "prog_tensors_validation = torch.load('./test-tensors/progressive_rock_songs_test_tensor.pt')\n",
    "non_prog_tensors_validation = torch.load('./test-tensors/non_progressive_rock_songs_test_tensor.pt')\n",
    "# model/model_conv1d_norm_1_large.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_state_dict\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "## For the song\n",
    "device = get_device()\n",
    "model.to(\"cpu\")\n",
    "prog_true = 0\n",
    "prog_false = 0\n",
    "non_prog_true = 0\n",
    "non_prog_false = 0\n",
    "# for the individual snippets\n",
    "total_prog_true = 0\n",
    "total_prog_false = 0\n",
    "total_non_prog_true = 0\n",
    "total_non_prog_false = 0\n",
    "with torch.no_grad():  # Disable gradients during validation\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for obj in prog_tensors_validation:\n",
    "    total = len(obj)\n",
    "    it = 0\n",
    "    for i in obj:\n",
    "      i = i.reshape(1,160,216)\n",
    "      i = i.to(\"cpu\")\n",
    "      outputs = model(i)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      # print(predicted)\n",
    "      if(predicted.item() == 1):\n",
    "        it = it+1\n",
    "    \n",
    "    total_prog_true += it\n",
    "    total_prog_false += (total-it)\n",
    "    if(2*it >= total):\n",
    "      prog_true +=1\n",
    "    else:\n",
    "      prog_false +=1\n",
    "  for obj in non_prog_tensors_validation:\n",
    "    total = len(obj)\n",
    "    it = 0\n",
    "    for i in obj:\n",
    "      i = i.reshape(1,160,216)\n",
    "      outputs = model(i)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      # print(predicted)\n",
    "      if(predicted.item() == 0):\n",
    "        it = it+1\n",
    "    total_non_prog_true += it\n",
    "    total_non_prog_false += (total-it)\n",
    "    if(2*it >= total):\n",
    "      non_prog_true +=1\n",
    "    else:\n",
    "      non_prog_false +=1\n",
    "\n",
    "\n",
    "print(prog_true, prog_false)\n",
    "print(non_prog_false, non_prog_true)\n",
    "\n",
    "print(total_prog_true, total_prog_false)\n",
    "print(total_non_prog_false, total_non_prog_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = prog_true\n",
    "FN = prog_false\n",
    "FP = non_prog_false\n",
    "TN = non_prog_true\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Calculate Precision for the progressive class\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "# Calculate Recall (Sensitivity) for the progressive class\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "# Calculate Specificity for the progressive class\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "# Calculate F1 Score for the progressive class\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision (Progressive Class): {precision:.4f}\")\n",
    "print(f\"Recall (Progressive Class): {recall:.4f}\")\n",
    "print(f\"Specificity (Progressive Class): {specificity:.4f}\")\n",
    "print(f\"F1 Score (Progressive Class): {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
